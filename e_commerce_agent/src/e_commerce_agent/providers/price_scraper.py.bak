import re
import json
import logging
import httpx
import base64
import io
import os
import time
import random
import tempfile
import asyncio
from PIL import Image
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs
from typing import Dict, List, Optional, Any, Tuple, BinaryIO
from playwright.async_api import async_playwright, Page, Browser, BrowserContext
from dotenv import load_dotenv

# Make pytesseract truly optional
TESSERACT_AVAILABLE = False
try:
    import pytesseract
    from PIL import ImageEnhance, ImageFilter
    TESSERACT_AVAILABLE = True
except ImportError:
    logging.warning("pytesseract not installed. Some CAPTCHA solving capabilities will be limited.")

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

class StealthScraper:
    """CAPTCHA avoidance through stealth techniques and API alternatives."""
    
    def __init__(self):
        """Initialize the stealth scraper."""
        self.temp_dir = tempfile.mkdtemp(prefix="browser_data_")
        os.makedirs(os.path.join(self.temp_dir, "user_data"), exist_ok=True)
        
        # API keys for alternative data sources
        self.rainforest_api_key = os.getenv("RAINFOREST_API_KEY")
        self.use_rainforest = self.rainforest_api_key is not None
        
        # User agent rotation
        self.desktop_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:93.0) Gecko/20100101 Firefox/93.0",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36"
        ]
        
        self.mobile_agents = [
            "Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1",
            "Mozilla/5.0 (iPad; CPU OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1"
        ]
        
        logger.info(f"Initialized StealthScraper with data directory: {self.temp_dir}")
        
        if not self.use_rainforest:
            logger.warning("""
                Rainforest API key not found. For more reliable product data, consider:
                1. Signing up for Rainforest Data API at https://www.rainforestapi.com/
                2. Adding your API key as RAINFOREST_API_KEY in .env file
                
                Falling back to stealth browser techniques (less reliable).
            """)
    
    async def get_amazon_product_data(self, url: str) -> Dict[str, Any]:
        """
        Get Amazon product data using the most reliable method available.
        Tries Rainforest API first, then falls back to browser techniques.
        
        Args:
            url: Amazon product URL
            
        Returns:
            Dict containing product data
        """
        # Extract ASIN from URL
        asin = self._extract_asin_from_url(url)
        if not asin:
            logger.warning(f"Could not extract ASIN from URL: {url}")
            asin = "unknown"
        
        # Try Rainforest API first if available
        if self.use_rainforest and asin != "unknown":
            try:
                logger.info(f"Attempting to fetch product data via Rainforest API for ASIN: {asin}")
                product_data = await self._get_amazon_data_from_api(asin)
                if product_data:
                    logger.info(f"Successfully retrieved product data from Rainforest API for {asin}")
                    return {
                        "status": "success",
                        "source": "amazon",
                        "url": url,
                        "title": product_data.get("title"),
                        "price": product_data.get("price", {}).get("value"),
                        "price_text": f"${product_data.get('price', {}).get('value')}" if product_data.get("price", {}).get("value") else "Price not available",
                        "rating": f"{product_data.get('rating')} out of 5 stars" if product_data.get("rating") else "No ratings",
                        "features": product_data.get("features", [])[:5],
                        "availability": product_data.get("availability", {}).get("raw_text", "Unknown"),
                        "image_url": product_data.get("main_image", {}).get("link"),
                        "asin": asin
                    }
            except Exception as e:
                logger.error(f"Error fetching from Rainforest API: {str(e)}")
        
        # Fall back to browser techniques
        logger.info(f"Falling back to browser techniques for URL: {url}")
        return await self._get_product_data_with_browser(url)
    
    async def _get_amazon_data_from_api(self, asin: str) -> Dict[str, Any]:
        """
        Fetch Amazon product data from Rainforest API.
        
        Args:
            asin: Amazon product ASIN
            
        Returns:
            Dict containing product data
        """
        api_url = "https://api.rainforestapi.com/request"
        params = {
            "api_key": self.rainforest_api_key,
            "type": "product",
            "amazon_domain": "amazon.com",
            "asin": asin
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.get(api_url, params=params, timeout=30.0)
            if response.status_code == 200:
                data = response.json()
                product_data = data.get("product", {})
                
                # Log the raw price data for debugging
                price_data = product_data.get('price', {})
                logger.info(f"Raw price data from Rainforest API: {price_data}")
                
                # Additional price extraction from buybox if available
                buybox = product_data.get('buybox_winner', {})
                if buybox:
                    buybox_price = buybox.get('price', {})
                    logger.info(f"Buybox price data: {buybox_price}")
                    
                    # If main price is missing but buybox has price, use that
                    if not price_data.get('value') and buybox_price.get('value'):
                        price_data = buybox_price
                
                # Try to extract price from different locations
                extracted_price = None
                price_text = None
                
                # Method 1: Direct price.value
                if price_data and isinstance(price_data, dict):
                    extracted_price = price_data.get('value')
                    price_text = f"${extracted_price}" if extracted_price else None
                
                # Method 2: Try to get from buybox
                if not extracted_price and buybox and isinstance(buybox, dict):
                    buybox_price = buybox.get('price', {})
                    if isinstance(buybox_price, dict):
                        extracted_price = buybox_price.get('value')
                        price_text = buybox_price.get('raw')
                
                # Method 3: Check other offer listings
                if not extracted_price:
                    other_sellers = product_data.get('other_sellers', [])
                    if other_sellers and len(other_sellers) > 0:
                        for seller in other_sellers:
                            seller_price = seller.get('price', {})
                            if seller_price and isinstance(seller_price, dict):
                                seller_price_value = seller_price.get('value')
                                if seller_price_value:
                                    extracted_price = seller_price_value
                                    price_text = seller_price.get('raw') or f"${extracted_price}"
                                    logger.info(f"Extracted price from other seller: {extracted_price}")
                                    break
                
                # Method 4: Check for raw price text
                if not extracted_price and price_data:
                    raw_price = price_data.get('raw')
                    if raw_price:
                        logger.info(f"Found raw price text: {raw_price}")
                        # Try to extract numeric value from raw price
                        price_match = re.search(r'\$?([\d,]+\.?\d*)', raw_price)
                        if price_match:
                            price_str = price_match.group(1).replace(',', '')
                            try:
                                extracted_price = float(price_str)
                                price_text = raw_price
                                logger.info(f"Extracted price from raw text: {extracted_price}")
                            except ValueError:
                                logger.warning(f"Failed to convert price string to float: {price_str}")
                
                # Update product data with our extracted price
                if extracted_price:
                    # Create a proper price structure if it doesn't exist
                    if not isinstance(product_data.get('price'), dict):
                        product_data['price'] = {}
                    
                    product_data['price']['value'] = extracted_price
                    if price_text:
                        product_data['price']['raw'] = price_text
                    
                    logger.info(f"Successfully extracted price for ASIN {asin}: ${extracted_price}")
                else:
                    logger.warning(f"Could not extract price for ASIN {asin} from any data source")
                
                return product_data
            else:
                logger.error(f"Rainforest API error: {response.status_code} - {response.text}")
                return None
    
    def _extract_asin_from_url(self, url: str) -> Optional[str]:
        """Extract ASIN from Amazon URL."""
        patterns = [
            r'/dp/([A-Z0-9]{10})/?',
            r'/gp/product/([A-Z0-9]{10})/?',
            r'/ASIN/([A-Z0-9]{10})/?',
            r'/product/([A-Z0-9]{10})/?'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        return None
    
    async def _get_product_data_with_browser(self, url: str) -> Dict[str, Any]:
        """
        Get product data using stealth browser techniques.
        Uses multiple layers of anti-detection measures.
        
        Args:
            url: Product URL
            
        Returns:
            Dict containing product data
        """
        # Determine if we should use mobile or desktop user agent
        use_mobile = random.random() < 0.3  # 30% chance of using mobile
        user_agent = random.choice(self.mobile_agents if use_mobile else self.desktop_agents)
        
        # Create unique browser profile for this session
        browser_data_dir = os.path.join(self.temp_dir, "user_data", f"session_{int(time.time())}")
        os.makedirs(browser_data_dir, exist_ok=True)
        
        max_retries = 3
        current_retry = 0
        
        while current_retry < max_retries:
            try:
                async with async_playwright() as p:
                    # Different browser types on different attempts
                    if current_retry == 0:
                        browser_type = p.chromium
                    elif current_retry == 1:
                        browser_type = p.firefox
                    else:
                        browser_type = p.webkit
                    
                    # Launch with extensive anti-fingerprinting
                    browser = await browser_type.launch(
                        headless=True,
                        args=[
                            '--disable-blink-features=AutomationControlled',
                            '--disable-features=IsolateOrigins,site-per-process',
                            f'--user-agent={user_agent}',
                            '--disable-site-isolation-trials',
                            '--no-sandbox'
                        ]
                    )
                    
                    # Create context with realistic browser settings
                    viewport_width = 1920 if not use_mobile else 375
                    viewport_height = 1080 if not use_mobile else 812
                    
                    context = await browser.new_context(
                        user_agent=user_agent,
                        viewport={'width': viewport_width, 'height': viewport_height},
                        device_scale_factor=random.choice([1, 2]) if not use_mobile else 3,
                        locale=random.choice(['en-US', 'en-GB']),
                        timezone_id=random.choice(['America/New_York', 'America/Los_Angeles', 'Europe/London']),
                        geolocation={'latitude': 40.7128, 'longitude': -74.0060},
                        permissions=['geolocation'],
                        is_mobile=use_mobile
                    )
                    
                    # Add stealth scripts
                    await context.add_init_script("""
                        // Make detection of automation more difficult
                        Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                        Object.defineProperty(navigator, 'languages', { get: () => ['en-US', 'en'] });
                        
                        // Mask Chrome headless detection
                        if (window.chrome) {
                            window.chrome.runtime = {};
                        }
                        
                        // Make navigator properties undetectable
                        const originalQuery = window.navigator.permissions.query;
                        window.navigator.permissions.query = (parameters) => (
                            parameters.name === 'notifications' ?
                                Promise.resolve({ state: Notification.permission }) :
                                originalQuery(parameters)
                        );
                    """)
                    
                    # Create new page and navigate with full retry logic
                    page = await context.new_page()
                    
                    # Add request interception to modify headers
                    await page.route('**/*', lambda route: route.continue_(
                        headers={
                            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                            'Accept-Language': 'en-US,en;q=0.9',
                            'Cache-Control': 'max-age=0',
                            'Connection': 'keep-alive',
                            'Sec-Fetch-Dest': 'document',
                            'Sec-Fetch-Mode': 'navigate',
                            'Sec-Fetch-Site': 'none',
                            'Sec-Fetch-User': '?1',
                            'Upgrade-Insecure-Requests': '1',
                            'DNT': '1'
                        }
                    ))
                    
                    # Add realistic human behavior
                    await self._add_human_behavior(page)
                    
                    # Load the URL with proxy if needed
                    try:
                        logger.info(f"Loading page: {url}")
                        
                        # Random delay before navigation
                        await page.wait_for_timeout(random.randint(1000, 3000))
                        
                        # Navigate with timeout
                        response = await page.goto(url, wait_until='domcontentloaded', timeout=60000)
                        
                        # Check response
                        if not response or response.status >= 400:
                            logger.warning(f"Got HTTP error: {response.status if response else 'No response'}")
                            current_retry += 1
                            continue
                        
                        # Check if page has anti-bot measures
                        if await self._is_blocked(page):
                            logger.warning(f"Detected anti-bot measures on attempt {current_retry + 1}")
                            current_retry += 1
                            continue
                            
                        # Add more human-like behavior
                        await self._simulate_human_behavior(page)
                        
                        # Extract product data
                        return await self._extract_product_data(page, url)
                        
                    except Exception as e:
                        logger.error(f"Error during page load: {str(e)}")
                        current_retry += 1
                        continue
                        
            except Exception as e:
                logger.error(f"Browser error on attempt {current_retry + 1}: {str(e)}")
                current_retry += 1
                
        # If all retries failed, return error
        return {
            "status": "error",
            "message": "Failed to access product data after multiple attempts",
            "url": url
        }
    
    async def _add_human_behavior(self, page: Page):
        """Add human-like behavior to the page."""
        # Set common cookies
        await page.evaluate("""() => {
            document.cookie = "session-id=" + Math.random().toString(36).substring(2, 15);
            document.cookie = "session-token=" + Math.random().toString(36).substring(2, 32);
        }""")
        
        # Impersonate common browser plugins
        await page.add_init_script("""
        if (!window.navigator.plugins) {
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
        }
        if (!window.navigator.mimeTypes) {
            Object.defineProperty(navigator, 'mimeTypes', {
                get: () => [1, 2, 3, 4, 5],
            });
        }
        """)
        
        # Random mouse movements
        await page.mouse.move(
            random.randint(100, 500),
            random.randint(100, 500)
        )
        
    async def _is_blocked(self, page: Page) -> bool:
        """
        Check if the page has anti-bot measures or blocks.
        
        Args:
            page: Playwright page
            
        Returns:
            bool: True if blocked, False otherwise
        """
        page_content = await page.content()
        block_indicators = [
            "robot", "captcha", "automated access", "verify you're a human",
            "unusual traffic", "bot", "security challenge", "suspicious activity",
            "to continue to amazon", "sorry, we just need to make sure"
        ]
        
        page_title = await page.title()
        if any(indicator in page_title.lower() for indicator in ["robot", "captcha", "verify", "check"]):
            return True
            
        return any(indicator in page_content.lower() for indicator in block_indicators)
    
    async def _simulate_human_behavior(self, page: Page):
        """Simulate realistic human browsing behavior."""
        # Random initial wait
        await page.wait_for_timeout(random.randint(1000, 3000))
        
        # Random scroll behavior
        scroll_times = random.randint(2, 5)
        for i in range(scroll_times):
            await page.evaluate(f"window.scrollBy(0, {random.randint(300, 700)})")
            await page.wait_for_timeout(random.randint(500, 1500))
        
        # Move mouse to random positions
        for _ in range(random.randint(2, 4)):
            await page.mouse.move(
                random.randint(100, 800),
                random.randint(100, 600)
            )
            await page.wait_for_timeout(random.randint(300, 700))
        
        # Scroll back up partially
        if random.random() < 0.7:  # 70% chance
            await page.evaluate(f"window.scrollBy(0, {random.randint(-400, -100)})")
            await page.wait_for_timeout(random.randint(500, 1000))
    
    async def _extract_product_data(self, page: Page, url: str) -> Dict[str, Any]:
        """
        Extract product data from the page.
        Uses multiple selector strategies to maximize success.
        
        Args:
            page: Playwright page
            url: Original URL
            
        Returns:
            Dict containing product data
        """
        try:
            asin = self._extract_asin_from_url(url) or "unknown"
            
            # Try to extract price from structured data first (most reliable)
            price, price_text = await self._extract_price_from_structured_data(page)
            
            # Multi-strategy title extraction
            title = await self._extract_text_with_fallbacks(page, [
                "#productTitle", 
                ".product-title", 
                "h1", 
                '[data-component-type="s-product-title"]'
            ])
            
            # If price wasn't in structured data, try multiple visual selectors
            if price is None:
                # Multi-strategy price extraction - ensure we wait for prices to load
                try:
                    # Wait for price elements to be visible - try multiple common selectors
                    price_selectors = [
                        ".a-price", 
                        "#priceblock_ourprice", 
                        ".a-color-price",
                        '[data-a-color="price"]',
                        '#corePrice_feature_div .a-offscreen',
                        '.priceToPay .a-offscreen',
                        '#corePriceDisplay_desktop_feature_div .a-offscreen',
                        '.a-price-whole',
                        '[data-asin] .a-price .a-offscreen',
                        '#price',
                        '.price-large'
                    ]
                    
                    for price_selector in price_selectors:
                        try:
                            # Wait with short timeouts to avoid long delays
                            await page.wait_for_selector(price_selector, timeout=2000, state="visible")
                            logger.info(f"Price element found with selector: {price_selector}")
                            break
                        except Exception:
                            continue
                except Exception as e:
                    logger.warning(f"Timed out waiting for price element: {str(e)}")
                
                # Now try to extract the price with many selector strategies
                price_selectors = [
                    ".a-price .a-offscreen",  # Amazon primary price
                    "#priceblock_ourprice",  # Amazon old price element
                    "#priceblock_dealprice",  # Amazon deals
                    ".a-color-price",  # General Amazon price
                    ".a-price",  # Another Amazon price format
                    "#price_inside_buybox",  # Buybox price
                    "#corePrice_feature_div .a-offscreen",  # New Amazon price
                    "#corePriceDisplay_desktop_feature_div .a-offscreen",  # Another variation
                    '[data-a-color="price"] .a-offscreen',  # Generic Amazon price
                    ".a-price .a-price-whole",  # Just the whole price part (will need decimals separately)
                    "#price",  # Generic price id
                    ".price-large",  # Amazon warehouse deals
                    ".priceToPay .a-offscreen",  # Another Amazon price format
                    "[data-asin] .a-price .a-offscreen",  # Product grid price
                    ".a-price-whole",  # Price whole part only
                    ".apexPriceToPay .a-offscreen",  # Another common pattern
                    ".a-section .a-price .a-offscreen"  # Section containing price
                ]
                
                # Try to find price with each selector
                price_text = await self._extract_text_with_fallbacks(page, price_selectors)
                
                # If still no price, try JavaScript evaluation to extract price directly from DOM
                if not price_text:
                    try:
                        price_text = await page.evaluate("""
                            () => {
                                // Try to find price in multiple ways
                                const priceElements = [
                                    ...document.querySelectorAll('.a-price .a-offscreen'),
                                    ...document.querySelectorAll('[data-a-color="price"]'),
                                    ...document.querySelectorAll('#priceblock_ourprice'),
                                    ...document.querySelectorAll('#priceblock_dealprice'),
                                    ...document.querySelectorAll('.priceToPay .a-offscreen'),
                                    ...document.querySelectorAll('#corePrice_feature_div .a-offscreen'),
                                    ...document.querySelectorAll('#corePriceDisplay_desktop_feature_div .a-offscreen'),
                                    ...document.querySelectorAll('.apexPriceToPay .a-offscreen'),
                                    document.querySelector('#price'),
                                    document.querySelector('.offer-price'),
                                    document.querySelector('.priceToPay')
                                ].filter(el => el);
                                
                                for (const el of priceElements) {
                                    if (el.textContent && el.textContent.includes('$')) {
                                        return el.textContent.trim();
                                    }
                                }
                                
                                // Enhanced scan for price in ANY element with $ sign
                                try {
                                    const allPriceTexts = [];
                                    const allElements = document.querySelectorAll('*');
                                    for (const el of allElements) {
                                        if (el.childNodes.length === 1 && 
                                            el.textContent && 
                                            el.textContent.includes('$') && 
                                            el.textContent.length < 20 &&
                                            !el.textContent.toLowerCase().includes('shipping') &&
                                            !el.textContent.toLowerCase().includes('delivery') &&
                                            !el.textContent.toLowerCase().includes('subtotal')) {
                                            allPriceTexts.push(el.textContent.trim());
                                        }
                                    }
                                    
                                    // Pick the most likely price (shortest valid price format)
                                    if (allPriceTexts.length > 0) {
                                        // Sort by length (shortest first) as it's likely to be just the price
                                        allPriceTexts.sort((a, b) => a.length - b.length);
                                        return allPriceTexts[0];
                                    }
                                } catch (e) {
                                    console.error("Error in comprehensive price scan:", e);
                                }
                                
                                return null;
                            }
                        """)
                        if price_text:
                            logger.info(f"Found price via JavaScript: {price_text}")
                    except Exception as e:
                        logger.error(f"Error using JavaScript to find price: {e}")
                
                # Last resort: Take screenshot and look for price visual pattern
                if not price_text:
                    try:
                        await page.screenshot(path='/tmp/product_page.png')
                        logger.info("Took screenshot for debugging price extraction")
                        
                        # Try one more time with an expanded search space and more patient waiting
                        await page.wait_for_timeout(2000)  # Wait a bit longer for dynamic content
                        
                        # Try a more patient JavaScript approach
                        price_text = await page.evaluate("""
                            () => {
                                // Look specifically for prices in the right sidebar (most common location)
                                const rightSidebar = document.querySelector('#rightCol, #centerCol, #ppd');
                                if (rightSidebar) {
                                    const pricePattern = /\$\d+(\.\d{2})?/;
                                    const allText = rightSidebar.innerText;
                                    const matches = allText.match(pricePattern);
                                    if (matches && matches.length > 0) {
                                        return matches[0];
                                    }
                                }
                                
                                // Generic search throughout the page
                                const textContent = document.body.innerText;
                                const priceMatches = textContent.match(/\$\d+(\.\d{2})?/g);
                                if (priceMatches && priceMatches.length > 0) {
                                    // Filter out implausibly large or small values
                                    const validPrices = priceMatches
                                        .map(p => parseFloat(p.replace('$', '')))
                                        .filter(p => p >= 1 && p <= 5000);
                                    
                                    if (validPrices.length > 0) {
                                        // Return the middle value as it's most likely to be the actual price
                                        validPrices.sort((a, b) => a - b);
                                        const midIndex = Math.floor(validPrices.length / 2);
                                        return '$' + validPrices[midIndex].toFixed(2);
                                    }
                                }
                                
                                return null;
                            }
                        """)
                        if price_text:
                            logger.info(f"Found price via extended JavaScript search: {price_text}")
                    except Exception as e:
                        logger.error(f"Error in last-resort price extraction: {e}")
                
                # Clean and extract price if we found text
                if price_text:
                    # Clean price text - sometimes it contains extra characters
                    price_text = price_text.strip()
                    
                    # Remove non-numeric characters except decimal point
                    price_str = re.sub(r'[^\d.]', '', price_text)
                    try:
                        price = float(price_str)
                        
                        # CRITICAL FIX: Perform sanity check on price
                        if price > 10000 or price < 1:
                            logger.warning(f"Extracted price ${price} is outside reasonable range for {title}. Might be incorrect.")
                            
                            # Product type specific checks
                            if title and any(keyword in title.lower() for keyword in ['shoe', 'trainer', 'sneaker']):
                                logger.warning(f"This appears to be footwear which typically costs $30-$200, not ${price}")
                                # Try alternative price extraction or set to None
                                price = None
                                price_text = "Price unavailable (error in extraction)"
                    except ValueError:
                        price = None
            
            # Multi-strategy rating extraction
            rating = await self._extract_text_with_fallbacks(page, [
                "#acrPopover", 
                ".a-icon-star", 
                ".reviewCountTextLinked", 
                '[data-hook="rating-out-of-text"]',
                '[data-hook="rating-snippet"]',
                '#averageCustomerReviews .a-icon-alt'
            ])
            
            # Multi-strategy features extraction  
            features = []
            feature_selectors = [
                "#feature-bullets .a-list-item",
                ".product-facts .a-list-item",
                ".bundle-components-list .a-list-item",
                "#feature-bullets li",
                ".a-unordered-list .a-list-item"
            ]
            
            for selector in feature_selectors:
                elements = await page.query_selector_all(selector)
                for element in elements:
                    text = await element.text_content()
                    text = text.strip()
                    if text:
                        features.append(text)
                
                if features:
                    break
            
            # Multi-strategy availability extraction
            availability = await self._extract_text_with_fallbacks(page, [
                "#availability", 
                "#deliveryMessageMirId", 
                ".a-box-inner .a-color-success",
                '[data-feature-name="availability"]',
                '.a-color-success',
                '#availability span',
                '.a-box-inner span'
            ])
            
            # Image extraction
            image_url = await self._extract_attribute_with_fallbacks(page, [
                "#landingImage", 
                ".image-swatch .a-declarative",
                ".image-stretch",
                "img[data-old-hires]",
                "#imgTagWrapperId img",
                ".imgTagWrapper img"
            ], "src")
            
            # Extract image URL from alternative attribute if needed
            if not image_url:
                image_url = await self._extract_attribute_with_fallbacks(page, [
                    "img[data-old-hires]",
                    "img[data-a-dynamic-image]",
                    "#imgBlkFront"
                ], "data-old-hires")
            
            # Take a screenshot of the page for debugging
            logger.info(f"Extracted product data from {url}: {title[:30]}...")
            
            # Ensure we have at least placeholder price text if price is None
            if not price_text or price_text == "null":
                price_text = "Price not available"
            
            # Better price display if we have a number
            if price is not None:
                price_text = f"${price:.2f}"
            
            # CRITICAL FIX: Always set source to "amazon" for Amazon URLs
            source = "amazon"
            if "walmart" in url.lower():
                source = "walmart"
            elif "bestbuy" in url.lower():
                source = "bestbuy"
            elif "target" in url.lower():
                source = "target"
            elif "costco" in url.lower():
                source = "costco"
                
            logger.info(f"Setting source to {source} for URL: {url}")
            
            return {
                "status": "success",
                "source": source,  # FIXED: Always use proper source
                "url": url,
                "title": title or "Unknown Product",
                "price": price,
                "price_text": price_text,
                "rating": rating or "No ratings",
                "features": features[:5],
                "availability": availability or "Unknown",
                "image_url": image_url,
                "asin": asin
            }
            
        except Exception as e:
            logger.error(f"Error extracting product data: {str(e)}")
            
            # Even in case of error, ensure source is set properly for Amazon URLs
            source = "unknown"
            if "amazon" in url.lower():
                source = "amazon"
            elif "walmart" in url.lower():
                source = "walmart"
            elif "bestbuy" in url.lower():
                source = "bestbuy"
                
            return {
                "status": "error",
                "message": f"Failed to extract product data: {str(e)}",
                "source": source,  # Use correct source even in error cases
                "url": url
            }
    
    async def _extract_text_with_fallbacks(self, page: Page, selectors: List[str]) -> Optional[str]:
        """
        Try to extract text using multiple selectors as fallbacks.
        
        Args:
            page: Playwright page
            selectors: List of CSS selectors to try
            
        Returns:
            Text content or None if not found
        """
        for selector in selectors:
            try:
                element = await page.query_selector(selector)
                if element:
                    text = await element.text_content()
                    if text:
                        return text.strip()
            except Exception:
                continue
        
        return None
    
    async def _extract_attribute_with_fallbacks(
        self, page: Page, selectors: List[str], attribute: str
    ) -> Optional[str]:
        """
        Try to extract an attribute using multiple selectors as fallbacks.
        
        Args:
            page: Playwright page
            selectors: List of CSS selectors to try
            attribute: Attribute name to extract
            
        Returns:
            Attribute value or None if not found
        """
        for selector in selectors:
            try:
                element = await page.query_selector(selector)
                if element:
                    value = await element.get_attribute(attribute)
                    if value:
                        return value
            except Exception:
                continue
        
        return None
    
    async def _extract_price_from_structured_data(self, page: Page) -> Tuple[Optional[float], Optional[str]]:
        """
        Extract price from structured JSON-LD data on the page.
        This is often more reliable than scraping visible elements.
        
        Args:
            page: Playwright page
            
        Returns:
            Tuple of (price as float, price as string)
        """
        try:
            # First try the most reliable direct DOM method - this works better than JSON-LD for Amazon
            direct_price = await page.evaluate("""
                () => {
                    // Amazon price extraction optimized for latest page structure
                    try {
                        // Try span.a-price first (most common current format)
                        const priceSpans = document.querySelectorAll('span.a-price span.a-offscreen');
                        if (priceSpans.length > 0) {
                            // Usually the first price is the main one
                            const priceText = priceSpans[0].textContent.trim();
                            // Verify it's a price
                            if (priceText.includes('$')) {
                                return {text: priceText, source: 'a-price-span'};
                            }
                        }
                        
                        // Try more specific price selectors used by Amazon
                        const priceSelectors = [
                            '#priceblock_ourprice',
                            '#priceblock_dealprice', 
                            '.a-price .a-offscreen',
                            '#corePrice_feature_div .a-offscreen',
                            '#price_inside_buybox',
                            '.priceToPay .a-offscreen',
                            '#sns-base-price',
                            '.a-spacing-micro .a-price .a-offscreen', // Used on many product pages
                            '.apexPriceToPay .a-offscreen'            // Another common location
                        ];
                        
                        for (const selector of priceSelectors) {
                            const element = document.querySelector(selector);
                            if (element && element.textContent) {
                                const text = element.textContent.trim();
                                if (text.includes('$')) {
                                    return {text: text, source: selector};
                                }
                            }
                        }
                        
                        // Try searching specific divs that commonly contain price
                        const priceDivs = [
                            'corePriceDisplay_desktop_feature_div',
                            'corePrice_feature_div',
                            'corePrice_desktop',
                            'price',
                            'buyNew',
                            'newOfferShippingMessage'
                        ];
                        
                        for (const divId of priceDivs) {
                            const div = document.getElementById(divId);
                            if (div) {
                                // Look for any text with $ sign in this div
                                const priceText = Array.from(div.querySelectorAll('*'))
                                    .map(el => el.textContent)
                                    .find(text => text && text.includes('$') && text.length < 15);
                                
                                if (priceText) {
                                    return {text: priceText.trim(), source: `div#${divId}`};
                                }
                            }
                        }
                        
                        // Last resort - scan all elements for price text
                        const allElements = document.querySelectorAll('*');
                        for (const el of allElements) {
                            if (el.childNodes.length === 1 && 
                                el.textContent && 
                                el.textContent.includes('$') && 
                                el.textContent.length < 15 &&
                                !el.textContent.toLowerCase().includes('shipping') &&
                                !el.textContent.toLowerCase().includes('total')) {
                                return {text: el.textContent.trim(), source: 'generic-element'};
                            }
                        }
                    } catch (e) {
                        console.error("Error in price extraction:", e);
                    }
                    
                    return null;
                }
            """)
            
            if direct_price and direct_price.get('text'):
                price_text = direct_price.get('text')
                source = direct_price.get('source', 'direct-dom')
                logger.info(f"Found price via direct DOM extraction: {price_text} (source: {source})")
                
                # Extract numeric price
                price_match = re.search(r'\$?([\d,]+\.?\d*)', price_text)
                if price_match:
                    price_str = price_match.group(1).replace(',', '')
                    try:
                        price = float(price_str)
                        # Basic sanity check for prices
                        if 1 <= price <= 10000:
                            return price, price_text
                        else:
                            logger.warning(f"Direct price {price} is outside reasonable range")
                    except ValueError:
                        logger.warning(f"Could not convert price text to float: {price_text}")
            
            # If direct method failed, try structured data approach
            structured_data = await page.evaluate("""
                () => {
                    // Look for JSON-LD data
                    const jsonldElements = document.querySelectorAll('script[type="application/ld+json"]');
                    const jsonData = [];
                    
                    for (const element of jsonldElements) {
                        try {
                            const parsedData = JSON.parse(element.textContent);
                            jsonData.push(parsedData);
                        } catch (e) {
                            // Ignore parsing errors
                        }
                    }
                    
                    return jsonData;
                }
            """)
            
            # Extract price from structured data
            for data in structured_data:
                # Handle different schema formats
                if "@type" in data:
                    if data["@type"] == "Product":
                        # Standard product schema
                        if "offers" in data:
                            offers = data["offers"]
                            if isinstance(offers, dict):
                                if "price" in offers:
                                    price = offers["price"]
                                    try:
                                        return float(price), f"${float(price):.2f}"
                                    except ValueError:
                                        pass
                            elif isinstance(offers, list):
                                for offer in offers:
                                    if "price" in offer:
                                        price = offer["price"]
                                        try:
                                            return float(price), f"${float(price):.2f}"
                                        except ValueError:
                                            pass
            
            # Try direct DOM extraction as an additional method for price
            try:
                price_data = await page.evaluate("""
                    () => {
                        // Amazon-specific price extraction
                        // Try to find the actual displayed price to the customer
                        
                        // First check for the buybox price (what customers actually pay)
                        let buyboxPriceElement = document.querySelector('#priceblock_ourprice, #priceblock_dealprice, .a-price .a-offscreen');
                        
                        if (buyboxPriceElement) {
                            return {
                                price: buyboxPriceElement.textContent.trim(),
                                source: 'buybox'
                            };
                        }
                        
                        // Then try the newer price elements
                        const newPriceElements = document.querySelectorAll('.priceToPay .a-offscreen, #corePrice_feature_div .a-offscreen, #corePriceDisplay_desktop_feature_div .a-offscreen');
                        if (newPriceElements.length > 0) {
                            return {
                                price: newPriceElements[0].textContent.trim(),
                                source: 'new_price_element'
                            };
                        }
                        
                        // Then try any element with $ that looks like a price
                        const allElements = document.querySelectorAll('*');
                        for (const el of allElements) {
                            const text = el.textContent;
                            if (text && 
                                text.includes('$') && 
                                text.length < 10 && 
                                /\$\d+(\.\d{2})?/.test(text) &&
                                !text.includes('list') &&
                                !text.includes('was') &&
                                !text.toLowerCase().includes('shipping')) {
                                
                                return {
                                    price: text.trim(),
                                    source: 'generic_price_element'
                                };
                            }
                        }
                        
                        return null;
                    }
                """)
                
                if price_data and price_data.get('price'):
                    price_text = price_data.get('price')
                    logger.info(f"Found price via DOM extraction: {price_text} (source: {price_data.get('source')})")
                    
                    # Extract numeric price
                    price_match = re.search(r'\$?([\d,]+\.?\d*)', price_text)
                    if price_match:
                        price_str = price_match.group(1).replace(',', '')
                        try:
                            price = float(price_str)
                            # Sanity check: most products are between $1 and $10000
                            if 1 <= price <= 10000:
                                return price, f"${price:.2f}"
                            else:
                                logger.warning(f"Price {price} is outside reasonable range, might be incorrect")
                        except ValueError:
                            pass
            except Exception as e:
                logger.error(f"Error during direct DOM price extraction: {e}")
            
            # Also check for inline variable declarations that might contain price
            price_variables = await page.evaluate("""
                () => {
                    // Look for common price variables in scripts
                    const scripts = document.querySelectorAll('script:not([src])');
                    let priceInfo = null;
                    
                    // Common price patterns in Amazon scripts
                    const patterns = [
                        /priceAmount['"]\s*:\s*([\d\.]+)/i,
                        /price['"]\s*:\s*([\d\.]+)/i,
                        /buyingPrice['"]\s*:\s*([\d\.]+)/i
                    ];
                    
                    for (const script of scripts) {
                        const content = script.textContent;
                        for (const pattern of patterns) {
                            const match = pattern.exec(content);
                            if (match && match[1]) {
                                try {
                                    const price = parseFloat(match[1]);
                                    if (!isNaN(price) && price > 0 && price < 10000) {
                                        return price;
                                    }
                                } catch (e) {
                                    // Ignore parsing errors
                                }
                            }
                        }
                    }
                    
                    return null;
                }
            """)
            
            if price_variables:
                # Perform sanity check on price from variables
                if 1 <= price_variables <= 10000:
                    logger.info(f"Found price via script variables: ${price_variables:.2f}")
                    return float(price_variables), f"${float(price_variables):.2f}"
                else:
                    logger.warning(f"Price from variables {price_variables} is outside reasonable range")
            
            return None, None
            
        except Exception as e:
            logger.error(f"Error extracting structured data: {str(e)}")
            return None, None
    
    def cleanup(self):
        """Clean up temporary files and data."""
        try:
            import shutil
            shutil.rmtree(self.temp_dir, ignore_errors=True)
            logger.info(f"Cleaned up temporary directory: {self.temp_dir}")
        except Exception as e:
            logger.error(f"Error cleaning up temporary files: {str(e)}")


class PriceScraper:
    def __init__(self):
        """Initialize the price scraper."""
        # Initialize user agent rotation
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15"
        ]
        
        # For desktop specific operations
        self.desktop_agents = self.user_agents
        
        self.headers = {
            "User-Agent": random.choice(self.user_agents),
            "Accept-Language": "en-US,en;q=0.9",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "sec-ch-ua": '"Chromium";v="124", "Google Chrome";v="124", "Not-A.Brand";v="99"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "document",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "none",
            "sec-fetch-user": "?1",
            "upgrade-insecure-requests": "1",
            "Cache-Control": "max-age=0",
            "Connection": "keep-alive",
            "DNT": "1",
            "Pragma": "no-cache"
        }
        self.timeout = 20.0
        
        # Initialize proxy settings
        self.proxy_username = os.getenv("PROXY_USERNAME")
        self.proxy_password = os.getenv("PROXY_PASSWORD")
        self.proxy_host = os.getenv("PROXY_HOST")
        self.proxy_port = os.getenv("PROXY_PORT")
        
        # Support for Rainforest API
        self.use_rainforest = "RAINFOREST_API_KEY" in os.environ and os.environ["RAINFOREST_API_KEY"]
        
        # Initialize stealth scraper
        self.stealth_scraper = StealthScraper()
        
        # Save cookies between sessions
        self.cookies_dir = os.path.join(tempfile.gettempdir(), "ecommerce_cookies")
        os.makedirs(self.cookies_dir, exist_ok=True)
        
        if not all([self.proxy_username, self.proxy_password, self.proxy_host, self.proxy_port]):
            logger.warning("Proxy credentials not fully configured. Some features may be limited.")

    async def _get_proxy_url(self) -> str:
        """Get the proxy URL with authentication."""
        if all([self.proxy_username, self.proxy_password, self.proxy_host, self.proxy_port]):
            return f"http://{self.proxy_username}:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}"
        return None

    async def get_product_details(self, url: str) -> Dict[str, Any]:
        """
        Fetch product details from the given URL using the most reliable method.
        This updated version uses API-first approach with browser fallback.
        """
        parsed_url = urlparse(url)
        domain = parsed_url.netloc.lower()
        
        # Force proper source identification
        source = "unknown"
        if "amazon" in domain or "amazon" in url.lower() or "a.co" in domain:
            source = "amazon"
        elif "target" in domain or "target.com" in url.lower():
            source = "target"
        elif "bestbuy" in domain or "best-buy" in url.lower() or "bestbuy" in url.lower():
            source = "bestbuy"
        elif "walmart" in domain or "walmart" in url.lower():
            source = "walmart"
        elif "costco" in domain or "costco.com" in url.lower():
            source = "costco"
            
        logger.info(f"IDENTIFIED SOURCE AS: {source} FOR URL: {url}")
        
        try:
            # Fix source identification by checking domains more robustly
            if source == "amazon":
                # Use the new stealth strategy and ensure source is set properly
                result = await self.stealth_scraper.get_amazon_product_data(url)
                # Fix source if needed (sometimes it might come back as 'www' or other value)
                if result:
                    if result.get("status") == "success":
                        result["source"] = "amazon"  # FORCE source to be amazon
                    return result
            elif source == "target":
                # Call the Target-specific scraper
                result = await self.scrape_target(url)
                if result.get("status") == "success":
                    result["source"] = "target"
                return result
            elif source == "bestbuy":
                # Call the Best Buy-specific scraper
                result = await self.scrape_bestbuy(url)
                if result.get("status") == "success":
                    result["source"] = "bestbuy"
                return result
            elif source == "walmart":
                # Call the Walmart-specific scraper
                result = await self.scrape_walmart(url)
                if result.get("status") == "success":
                    result["source"] = "walmart"
                return result
            else:
                # For unknown sources, make best effort to extract info
                # Try to determine the most likely source based on URL patterns
                if "amazon" in url.lower():
                    source = "amazon"
                    result = await self.stealth_scraper.get_amazon_product_data(url)
                    if result.get("status") == "success":
                        result["source"] = "amazon"  # FORCE source to be amazon
                    return result
                elif "target" in url.lower():
                    source = "target"
                    return await self.scrape_target(url)
                elif "bestbuy" in url.lower() or "best-buy" in url.lower():
                    source = "bestbuy"
                    return await self.scrape_bestbuy(url)
                elif "walmart" in url.lower():
                    source = "walmart"
                    return await self.scrape_walmart(url)
                
                return {
                    "status": "error",
                    "message": f"Unsupported website: {domain}",
                    "source": source,
                    "url": url
                }
        except Exception as e:
            logger.error(f"Error scraping {url}: {str(e)}")
            # Try to determine source even in case of error
            return {
                "status": "error",
                "message": f"Failed to scrape product: {str(e)}",
                "source": source,  # Use the source we determined earlier
                "url": url
            }

    def _extract_title_from_url(self, url: str) -> str:
        """Extract a reasonable product title from the URL."""
        try:
            # Extract from path
            path = urlparse(url).path
            
            # Remove file extensions and trailing slashes
            path = re.sub(r'\.\w+$', '', path).rstrip('/')
            
            # Split by slashes and get the last meaningful segment
            segments = [s for s in path.split('/') if s and len(s) > 1]
            
            if segments:
                # Try to find a segment that looks like a product title
                # Usually it's the last segment before query parameters
                raw_title = segments[-1]
                
                # Replace hyphens and underscores with spaces
                title = re.sub(r'[-_]', ' ', raw_title)
                
                # Capitalize words
                title = ' '.join(word.capitalize() for word in title.split())
                
                # Clean up common patterns
                title = re.sub(r'\b[A-Z0-9]{10,}\b', '', title)  # Remove ASIN-like strings
                title = re.sub(r'\s+', ' ', title).strip()  # Clean up whitespace
                
                if len(title) > 5:  # If we have something meaningful
                    return title
            
            # Fallback: Look for product name in query parameters
            query = urlparse(url).query
            query_params = parse_qs(query)
            
            for param_name in ['title', 'name', 'product', 'item']:
                if param_name in query_params:
                    return query_params[param_name][0]
            
            # Last resort
            for segment in segments:
                if len(segment) > 5 and not segment.isdigit():
                    return re.sub(r'[-_]', ' ', segment).title()
                    
            # Ultimate fallback
            return "Unknown Product"
            
        except Exception as e:
            logger.error(f"Error extracting title from URL: {str(e)}")
            return "Unknown Product"

    async def find_alternatives(self, product_details: Dict[str, Any], max_results: int = 3) -> List[Dict[str, Any]]:
        """
        Find alternative products on other sites based on the provided product details.
        Uses multiple search strategies to find the most relevant alternatives.
        
        Now includes specialized handlers for specific retailers.
        """
        if product_details.get("status") != "success":
            return []
        
        # Ensure source is properly set - fallback to extraction from URL if needed
        original_source = product_details.get('source', '').lower()
        url = product_details.get('url', '')
        
        # CRITICAL FIX: If source is "www" and URL contains amazon, set source to amazon
        if original_source == 'www' and 'amazon' in url.lower():
            logger.info(f"Fixing source from 'www' to 'amazon' for alternatives search: {url}")
            product_details['source'] = 'amazon'
            original_source = 'amazon'
        
        # Log the search attempt for better debugging
        logger.info(f"Searching for alternatives for product from {product_details.get('source', 'unknown')} with title: {product_details.get('title', 'Unknown')}")
        
        # If we don't have a price, try to get it from the price_text
        if product_details.get('price') is None and product_details.get('price_text'):
            try:
                price_text = product_details.get('price_text', '')
                price_match = re.search(r'\$?([\d,]+\.?\d*)', price_text)
                if price_match:
                    price_str = price_match.group(1).replace(',', '')
                    price = float(price_str)
                    # Add it to the product details
                    product_details['price'] = price
                    logger.info(f"Extracted price ${price} from price_text '{price_text}' for alternatives search")
            except Exception as e:
                logger.error(f"Failed to extract price from price_text: {e}")
        
        # Set a global timeout for the entire alternatives search process
        start_time = time.time()
        global_timeout = 25.0  # 25 seconds maximum for the entire alternatives search
        
        # Store alternatives from all strategies
        all_alternatives = []
        
        # Special retailer-specific handling
        # This helps us handle specific retailers with specialized methods
        if original_source.lower() == 'walmart':
            try:
                # Use our specialized Walmart alternatives finder
                walmart_timeout = 20.0
                
                logger.info(f"Using specialized Walmart alternatives finder with {walmart_timeout}s timeout")
                
                # Create a task for the Walmart alternatives
                walmart_task = asyncio.create_task(
                    self._find_walmart_alternatives(product_details, max_results)
                )
                
                # Create a timeout task
                timeout_task = asyncio.create_task(asyncio.sleep(walmart_timeout))
                
                # Wait for either task to complete
                done, pending = await asyncio.wait(
                    {walmart_task, timeout_task},
                    return_when=asyncio.FIRST_COMPLETED
                )
                
                # Cancel pending tasks
                for task in pending:
                    task.cancel()
                
                # If the Walmart alternatives task completed, process results
                if walmart_task in done:
                    walmart_alternatives = await walmart_task
                    if walmart_alternatives:
                        logger.info(f"Specialized Walmart finder found {len(walmart_alternatives)} alternatives")
                        all_alternatives.extend(walmart_alternatives)
                else:
                    logger.warning(f"Specialized Walmart finder timed out after {walmart_timeout}s")
            except Exception as e:
                logger.error(f"Error using specialized Walmart alternatives finder: {e}")
        
        # If we still don't have enough alternatives, try the standard methods
        if len(all_alternatives) < max_results and (time.time() - start_time) < global_timeout:
            source = product_details.get('source', 'unknown').lower()
            title = product_details.get('title', 'Unknown Product')
            current_price = product_details.get('price')
            current_rating = self._extract_rating_value(product_details.get('rating', '0'))
            
            # Create multiple search query strategies
            search_strategies = []
            
            # Strategy 1: Generate search queries from product title and details
            title_queries = self._generate_title_search_queries(title)
            search_strategies.append(("Title-based", title_queries))
            
            # Strategy 2: Use product category + key attributes if identified
            category = self._identify_product_category(title, url)
            attribute_queries = self._generate_attribute_search_queries(title, category)
            search_strategies.append(("Attribute-based", attribute_queries))
            
            # Strategy 3: Use brand + key model words
            brand_queries = self._generate_brand_search_queries(title)
            search_strategies.append(("Brand-based", brand_queries))
            
            # Create search URLs for different stores
            stores = {
                "amazon": lambda q: f"https://www.amazon.com/s?k={q}",
                "walmart": lambda q: f"https://www.walmart.com/search/?query={q}",
                "bestbuy": lambda q: f"https://www.bestbuy.com/site/searchpage.jsp?st={q}",
                "target": lambda q: f"https://www.target.com/s?searchTerm={q}",
                "costco": lambda q: f"https://www.costco.com/CatalogSearch?keyword={q}"
            }
            
            # Keep track of alternatives
            processed_stores = set()
            
            # Function to deduplicate alternatives
            def is_duplicate(alt):
                for existing_alt in all_alternatives:
                    if alt.get('url') == existing_alt.get('url'):
                        return True
                    if alt.get('title') and existing_alt.get('title') and alt.get('title') == existing_alt.get('title'):
                        return True
                return False
            
            # For each store (except the source store)
            for store_name, search_url_func in stores.items():
                # Skip if we've already processed this store or it's the original source
                if store_name == source or store_name in processed_stores:
                    continue
                    
                # Skip if we've reached max results
                if len(all_alternatives) >= max_results:
                    break
                    
                # Skip if we've exceeded our time limit
                if (time.time() - start_time) >= global_timeout:
                    logger.warning(f"Global timeout reached after {global_timeout}s")
                    break
                
                logger.info(f"Looking for alternatives at {store_name} for {title}")
                alt_product = None
                
                # Try each search strategy until one finds a result
                for strategy_name, queries in search_strategies:
                    if alt_product and alt_product.get("status") == "success":
                        break
                        
                    # Skip if we've exceeded our time limit for this strategy
                    if (time.time() - start_time) >= global_timeout:
                        break
                        
                    logger.info(f"Trying {strategy_name} search strategy for {store_name}")
                    
                    for query in queries:
                        # Skip if we've reached max results
                        if len(all_alternatives) >= max_results:
                            break
                            
                        # Skip if we've exceeded our time limit for this query
                        if (time.time() - start_time) >= global_timeout:
                            break
                            
                        if alt_product and alt_product.get("status") == "success":
                            break
                            
                        search_url = search_url_func(query)
                        logger.info(f"Searching {store_name} with query: {query}")
                        
                        try:
                            # Use a shorter timeout for each individual search
                            search_timeout = 7.0  # 7 seconds per search
                            
                            # Create a task for the search
                            search_task = asyncio.create_task(
                                self._get_top_search_result(store_name, search_url)
                            )
                            
                            # Create a timeout task
                            timeout_task = asyncio.create_task(asyncio.sleep(search_timeout))
                            
                            # Wait for either search to complete or timeout
                            done, pending = await asyncio.wait(
                                {search_task, timeout_task},
                                return_when=asyncio.FIRST_COMPLETED
                            )
                            
                            # Cancel pending tasks
                            for task in pending:
                                task.cancel()
                            
                            # If the search task completed, process results
                            if search_task in done:
                                alt_product = await search_task
                                
                                if alt_product and alt_product.get("status") == "success":
                                    logger.info(f"Found match at {store_name} using query: {query}")
                                    break
                            else:
                                # Search timed out
                                logger.warning(f"Search timed out for {store_name} with query: {query}")
                        except Exception as e:
                            logger.error(f"Error searching {store_name} with query {query}: {e}")
                
                # If we found an alternative for this store, process it
                if alt_product and alt_product.get("status") == "success":
                    # Skip if it's a duplicate of an existing alternative
                    if is_duplicate(alt_product):
                        logger.info(f"Skipping duplicate alternative from {store_name}")
                        continue
                        
                    # Mark this store as processed
                    processed_stores.add(store_name)
                    
                    # Combine data from multiple sources if needed
                    self._enrich_product_data(alt_product)
                    
                    alt_price = alt_product.get("price")
                    
                    # Apply sanity check for alternative prices
                    if alt_price is not None:
                        if alt_price > 10000 or alt_price < 1:
                            logger.warning(f"Possible incorrect alternative price detected: ${alt_price} for {alt_product.get('title')}")
                            if any(keyword in alt_product.get('title', '').lower() for keyword in ['shoe', 'trainer', 'sneaker']):
                                logger.info(f"Alternative appears to be footwear which typically costs $30-$200, not ${alt_price}")
                                # Don't add this alternative with suspicious price
                                continue

                    alt_rating_value = self._extract_rating_value(alt_product.get("rating", "0"))
                    
                    # Calculate price difference percentage if both prices exist
                    price_reason = ""
                    if current_price and alt_price:
                        price_diff_pct = ((current_price - alt_price) / current_price) * 100
                        if price_diff_pct > 3:  # More than 3% cheaper
                            price_reason = f"{abs(round(price_diff_pct))}% cheaper than {source.capitalize()}"
                        elif price_diff_pct < -3:  # More than 3% more expensive
                            price_reason = f"{abs(round(price_diff_pct))}% more expensive than {source.capitalize()}"
                        else:
                            price_reason = f"Similar price to {source.capitalize()}"
                    
                    # Create combined reason text based on real data
                    reasons = []
                    if price_reason:
                        reasons.append(price_reason)
                    if alt_rating_value > current_rating + 0.3:
                        reasons.append(f"Higher customer rating ({alt_rating_value:.1f} vs {current_rating:.1f})")
                    elif current_rating > alt_rating_value + 0.3:
                        reasons.append(f"Lower customer rating ({alt_rating_value:.1f} vs {current_rating:.1f})")
                    
                    if alt_product.get("availability") and "in stock" in alt_product.get("availability").lower():
                        reasons.append("In stock and ready to ship")
                    
                    # Join all reasons
                    reason = " | ".join(reasons) if reasons else "Alternative option"
                    
                    # Calculate holistic score based on real data
                    # Price score (0-50 points)
                    price_score = 25  # Default neutral
                    if current_price and alt_price:
                        # Lower price is better
                        price_diff_pct = ((current_price - alt_price) / current_price) * 100
                        price_score = min(50, max(0, 25 + price_diff_pct))
                    
                    # Rating score (0-30 points)
                    rating_score = (alt_rating_value / 5.0) * 30
                    
                    # Reviews volume score (0-10 points)
                    review_count_text = alt_product.get("review_count", "0")
                    try:
                        review_count = int(re.search(r'\d+', review_count_text).group()) if isinstance(review_count_text, str) else 0
                    except (AttributeError, ValueError):
                        review_count = 0
                    
                    review_volume_score = min(10, (review_count / 1000) * 10) if review_count else 0
                    
                    # Availability score (0-10 points)
                    availability = alt_product.get("availability", "Unknown")
                    availability_score = 10 if availability and "in stock" in availability.lower() else 5
                    
                    # Calculate total holistic score
                    holistic_score = price_score + rating_score + review_volume_score + availability_score
                    
                    # Determine if it's a better deal overall based on holistic score
                    is_better_deal = holistic_score > 50
                    
                    # Add to alternatives
                    alternative_data = {
                        "source": store_name,
                        "title": alt_product.get("title", "Unknown Product"),
                        "price": alt_price,
                        "url": alt_product.get("url", search_url),
                        "is_better_deal": is_better_deal,
                        "reason": reason,
                        "rating": alt_product.get("rating", "No ratings"),
                        "review_count": review_count,
                        "availability": alt_product.get("availability", "Unknown"),
                        "holistic_score": round(holistic_score, 1)
                    }
                    
                    all_alternatives.append(alternative_data)
                    logger.info(f"Added alternative from {store_name}: {alt_product.get('title')} for ${alt_price}")
        
        # Return all alternatives we've found, up to max_results
        if all_alternatives:
            # Sort by holistic score (best first)
            all_alternatives.sort(key=lambda x: x.get("holistic_score", 0), reverse=True)
            logger.info(f"Total alternatives found: {len(all_alternatives)}")
        else:
            logger.warning("No alternatives found through any strategy")
        
        return all_alternatives[:max_results]

    def _generate_title_search_queries(self, title: str) -> List[str]:
        """Generate search queries based on product title."""
        queries = []
        
        # Clean title for better search results
        search_title = title
        
        # Strategy 1: First few important words (standard)
        important_words = ' '.join(search_title.split()[:6])
        queries.append(important_words.replace(" ", "+"))
        
        # Strategy 2: Just use the essential words (first 3-4)
        essential_words = ' '.join(search_title.split()[:4])
        queries.append(essential_words.replace(" ", "+"))
        
        # Strategy 3: Exclude brand if it's the first word
        parts = search_title.split(" ", 1)
        if len(parts) > 1 and len(parts[0]) < 15:  # First word could be brand
            no_brand = parts[1]  # Use remainder for search
            queries.append(no_brand.replace(" ", "+"))
        
        return queries
    
    def _identify_product_category(self, title: str, url: str) -> str:
        """Identify the product category based on title and URL."""
        title_lower = title.lower()
        url_lower = url.lower()
        
        # Check for common product categories
        if any(word in title_lower or word in url_lower for word in ['shoe', 'trainer', 'sneaker', 'footwear']):
            return "shoes"
        elif any(word in title_lower or word in url_lower for word in ['laptop', 'notebook', 'computer']):
            return "computers"
        elif any(word in title_lower or word in url_lower for word in ['phone', 'smartphone', 'cell']):
            return "phones"
        elif any(word in title_lower or word in url_lower for word in ['tv', 'television', 'monitor', 'screen']):
            return "tvs"
        elif any(word in title_lower or word in url_lower for word in ['watch', 'smartwatch']):
            return "watches"
        elif any(word in title_lower or word in url_lower for word in ['headphone', 'earbud', 'earphone']):
            return "audio"
        elif any(word in title_lower or word in url_lower for word in ['camera', 'dslr', 'mirrorless']):
            return "cameras"
        else:
            return "general"
            
    def _generate_attribute_search_queries(self, title: str, category: str) -> List[str]:
        """Generate search queries based on product attributes for the given category."""
        queries = []
        title_lower = title.lower()
        
        # Extract potential brand name (usually first word)
        parts = title.split(" ", 1)
        brand = parts[0] if len(parts) > 1 else ""
        
        # Extract color if present
        color_match = re.search(r'(black|white|red|blue|green|yellow|gray|grey|brown|purple|pink|orange|gold|silver)', 
                               title_lower)
        color = color_match.group(1) if color_match else None
        
        # Extract size if present
        size_match = re.search(r'size\s+(\w+)', title_lower)
        size = size_match.group(1) if size_match else None
        
        # Extract model number if present
        model_match = re.search(r'model\s+([A-Za-z0-9\-]+)', title_lower)
        model = model_match.group(1) if model_match else None
        
        # Create category-specific queries
        if category == "shoes":
            # Shoes typically search by brand + type + gender/size
            if brand:
                queries.append(f"{brand}+{category}")
                if color:
                    queries.append(f"{brand}+{color}+{category}")
                if "women" in title_lower:
                    queries.append(f"{brand}+women+{category}")
                elif "men" in title_lower:
                    queries.append(f"{brand}+men+{category}")
        
        elif category == "computers":
            # Computer searches often include specs
            if brand:
                queries.append(f"{brand}+laptop")
                # Look for screen size
                screen_match = re.search(r'(\d+(\.\d+)?)\s*inch', title_lower)
                if screen_match:
                    screen_size = screen_match.group(1)
                    queries.append(f"{brand}+{screen_size}+inch+laptop")
        
        elif category == "phones":
            # Phone searches typically include model names/numbers
            if brand:
                queries.append(f"{brand}+phone")
                # Extract model if it exists
                if model:
                    queries.append(f"{brand}+{model}+phone")
                elif "pro" in title_lower:
                    queries.append(f"{brand}+pro+phone")
        
        # Add general attribute combinations for any category
        if brand and color:
            queries.append(f"{brand}+{color}")
        if brand and model:
            queries.append(f"{brand}+{model}")
        
        return queries
    
    def _generate_brand_search_queries(self, title: str) -> List[str]:
        """Generate search queries focused on brand and model."""
        queries = []
        
        # Extract potential brand (first word)
        parts = title.split(" ", 1)
        if len(parts) > 1:
            brand = parts[0]
            
            # Brand + next 1-2 words (likely model)
            model_words = parts[1].split()[:2]
            if model_words:
                queries.append(f"{brand}+{'+'.join(model_words)}")
            
            # Brand + product type words
            product_types = ["shoe", "trainer", "laptop", "computer", "phone", "tv", "watch"]
            for product_type in product_types:
                if product_type in title.lower():
                    queries.append(f"{brand}+{product_type}")
        
        return queries

    def _extract_rating_value(self, rating_text: str) -> float:
        """Extract numeric rating value from rating text."""
        try:
            # Try to extract a number from text like "4.5 out of 5 stars"
            match = re.search(r'(\d+(\.\d+)?)', rating_text)
            if match:
                return float(match.group(1))
            return 0.0
        except (ValueError, TypeError, AttributeError):
            return 0.0

    async def _get_top_search_result(self, store_name: str, search_url: str) -> Dict[str, Any]:
        """Get top search result from a store's search page."""
        logger.info(f"Searching for alternatives on {store_name} at {search_url}")
        
        try:
            # Select appropriate method based on store
            if store_name == "amazon":
                return await self._get_amazon_search_result(search_url)
            elif store_name == "walmart":
                return await self._get_walmart_search_result(search_url)
            elif store_name == "bestbuy":
                return await self._get_bestbuy_search_result(search_url)
            elif store_name == "target":
                return await self._get_target_search_result(search_url)
            else:
                # Generic fallback using browser approach
                return await self._get_generic_search_result(store_name, search_url)
        except Exception as e:
            logger.error(f"Error getting search result from {store_name}: {e}")
            return {
                "status": "error",
                "message": f"Failed to find alternatives on {store_name}: {str(e)}"
            }
    
    async def _get_target_search_result(self, search_url: str) -> Dict[str, Any]:
        """Get top search result from Target search page."""
        logger.info(f"Searching Target: {search_url}")
        
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                
                context = await browser.new_context(
                    user_agent=random.choice(self.user_agents),
                    viewport={"width": 1280, "height": 800}
                )
                
                # Add stealth script to avoid detection
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                """)
                
                page = await context.new_page()
                
                try:
                    # Navigate to search page
                    await page.goto(search_url, wait_until="domcontentloaded", timeout=20000)
                    
                    # Wait for search results to load
                    search_result_selectors = [
                        '[data-test="product-grid"] > div',
                        '[data-test="product-card-default"]',
                        '.styles__StyledCol-sc-fw90uk-0'
                    ]
                    
                    for selector in search_result_selectors:
                        try:
                            await page.wait_for_selector(selector, timeout=3000)
                            logger.info(f"Found Target search results with selector: {selector}")
                            break
                        except Exception:
                            continue
                    
                    # Extract top search results
                    product_data = await page.evaluate("""
                        () => {
                            // Find product elements (vary by page layout)
                            const productSelectors = [
                                '[data-test="product-grid"] > div',
                                '[data-test="product-card-default"]',
                                '.styles__StyledCol-sc-fw90uk-0'
                            ];
                            
                            let productElements = [];
                            for (const selector of productSelectors) {
                                const elements = document.querySelectorAll(selector);
                                if (elements.length > 0) {
                                    productElements = Array.from(elements);
                                    console.log(`Found ${elements.length} products with selector: ${selector}`);
                                    break;
                                }
                            }
                            
                            // Process only the top 3 products
                            const productLimit = Math.min(3, productElements.length);
                            const products = [];
                            
                            for (let i = 0; i < productLimit; i++) {
                                try {
                                    const element = productElements[i];
                                    
                                    // Find product link
                                    const linkElement = element.querySelector('a[data-test="product-title"], a[href^="/p/"]');
                                    if (!linkElement) continue;
                                    
                                    // Get product URL and title
                                    const url = linkElement.href;
                                    const title = linkElement.textContent.trim();
                                    
                                    // Find price
                                    let price = null;
                                    let priceText = null;
                                    
                                    // Try various price selectors
                                    const priceSelectors = [
                                        '[data-test="product-price"]',
                                        '[data-component="Price"]',
                                        '.styles__CurrentPriceWrapper-sc-1irel10-2'
                                    ];
                                    
                                    for (const selector of priceSelectors) {
                                        const priceElement = element.querySelector(selector);
                                        if (priceElement) {
                                            priceText = priceElement.textContent.trim();
                                            const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                            if (match) {
                                                price = parseFloat(match[1].replace(',', ''));
                                                break;
                                            }
                                        }
                                    }
                                    
                                    // If still no price, look for any element with $ sign
                                    if (!price) {
                                        const allElements = element.querySelectorAll('*');
                                        for (const el of allElements) {
                                            const text = el.textContent;
                                            if (text && 
                                                text.includes('$') && 
                                                text.length < 15 &&
                                                !text.toLowerCase().includes('shipping')) {
                                                
                                                priceText = text.trim();
                                                const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                                if (match) {
                                                    price = parseFloat(match[1].replace(',', ''));
                                                    break;
                                                }
                                            }
                                        }
                                    }
                                    
                                    // Get rating if available
                                    let rating = null;
                                    const ratingElement = element.querySelector('[data-test="ratings"], [data-test="star-rating"]');
                                    if (ratingElement) {
                                        // Try to extract numeric rating
                                        const ratingText = ratingElement.textContent.trim();
                                        const ratingMatch = ratingText.match(/(\\d+(\\.\\d+)?)/);
                                        if (ratingMatch) {
                                            rating = `${ratingMatch[1]} out of 5 stars`;
                                        } else {
                                            rating = ratingText;
                                        }
                                    }
                                    
                                    // Get image URL
                                    let imageUrl = null;
                                    const imageElement = element.querySelector('img');
                                    if (imageElement) {
                                        imageUrl = imageElement.src;
                                    }
                                    
                                    // Add product to results if we have at least title and URL
                                    if (title && url) {
                                        // Fix relative URLs to absolute
                                        const absoluteUrl = url.startsWith('http') ? url : 'https://www.target.com' + url;
                                        
                                        products.push({
                                            title,
                                            url: absoluteUrl,
                                            price,
                                            priceText: price ? (priceText || `$${price}`) : 'Price not available',
                                            rating: rating || 'No ratings',
                                            availability: 'In Stock', // Assumption for search results
                                            imageUrl
                                        });
                                    }
                                } catch (error) {
                                    console.error(`Error processing product element ${i}:`, error);
                                }
                            }
                            
                            return products;
                        }
                    """)
                    
                    # Take screenshot for debugging if no products found
                    if not product_data or len(product_data) == 0:
                        await page.screenshot(path="/tmp/target_search_error.png")
                        logger.warning("No products found in Target search, saved screenshot for debugging")
                        return {
                            "status": "error",
                            "message": "No products found in Target search results",
                            "source": "target"
                        }
                    
                    # Return the first valid product
                    for product in product_data:
                        if product.get("title") and product.get("url"):
                            logger.info(f"Found Target product: {product.get('title')[:30]}...")
                            return {
                                "status": "success",
                                "source": "target",
                                "url": product.get("url"),
                                "title": product.get("title"),
                                "price": product.get("price"),
                                "price_text": product.get("priceText", "Price not available"),
                                "rating": product.get("rating", "No ratings"),
                                "availability": "In Stock",  # Assume search results are in stock
                                "image_url": product.get("imageUrl")
                            }
                    
                    return {
                        "status": "error",
                        "message": "No valid products found in Target search results",
                        "source": "target"
                    }
                    
                except Exception as e:
                    logger.error(f"Error during Target search: {str(e)}")
                    await page.screenshot(path="/tmp/target_search_error.png")
                    return {
                        "status": "error",
                        "message": f"Failed to search Target: {str(e)}",
                        "source": "target"
                    }
                finally:
                    await browser.close()
                    
        except Exception as e:
            logger.error(f"Error initializing browser for Target search: {str(e)}")
            return {
                "status": "error",
                "message": f"Browser error: {str(e)}",
                "source": "target"
            }
    
    async def _get_generic_search_result(self, store_name: str, search_url: str) -> Dict[str, Any]:
        """Fallback method for any store without specific implementation."""
        logger.info(f"No specific search implementation for {store_name}")
        
        # Return error rather than generating synthetic data
        return {
            "status": "error",
            "message": f"No search implementation available for {store_name}"
        }

    async def _get_amazon_search_result(self, search_url: str) -> Dict[str, Any]:
        """Get top search result from Amazon search page using stealth techniques."""
        logger.info(f"Searching Amazon with URL: {search_url}")
        
        async with async_playwright() as p:
            # Use Chromium for better compatibility with Amazon
            browser = await p.chromium.launch(headless=True)
            
            # Create a more realistic browser context
            context = await browser.new_context(
                user_agent=random.choice(self.user_agents),
                viewport={"width": 1280, "height": 800},
                locale="en-US"
            )
            
            # Add stealth script to avoid detection
            await context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
            """)
            
            # Create page and navigate
            page = await context.new_page()
            
            try:
                # Random delay before navigation to appear more human-like
                await page.wait_for_timeout(random.randint(800, 2000))
                
                # Navigate to search page
                await page.goto(search_url, wait_until="domcontentloaded", timeout=30000)
                
                # Wait for search results to load with multiple selectors
                for selector in [
                    "[data-component-type='s-search-result']", 
                    ".s-result-item", 
                    ".sg-col-inner"
                ]:
                    try:
                        await page.wait_for_selector(selector, timeout=5000, state="visible")
                        logger.info(f"Search results found with selector: {selector}")
                        break
                    except Exception:
                        continue
                
                # Extract first few search results
                product_data = await page.evaluate("""
                    () => {
                        // Try multiple selectors for search results
                        const resultSelectors = [
                            "[data-component-type='s-search-result']", 
                            ".s-result-item:not(.AdHolder)", 
                            ".s-result-list .sg-col-inner"
                        ];
                        
                        let resultElements = [];
                        
                        // Try each selector until we find results
                        for (const selector of resultSelectors) {
                            resultElements = document.querySelectorAll(selector);
                            if (resultElements.length > 0) break;
                        }
                        
                        // Process up to 5 results
                        const results = [];
                        let processedCount = 0;
                        
                        for (let i = 0; i < resultElements.length && processedCount < 5; i++) {
                            const result = resultElements[i];
                            
                            // Skip sponsored results and other non-product items
                            if (result.innerText.includes('Sponsored') || 
                                !result.querySelector('a.a-link-normal') ||
                                result.classList.contains('AdHolder')) {
                                continue;
                            }
                            
                            // Extract product details
                            try {
                                // Get title
                                const titleElement = result.querySelector('h2 .a-link-normal') || 
                                                    result.querySelector('.a-size-medium.a-color-base') ||
                                                    result.querySelector('h2') ||
                                                    result.querySelector('.a-text-normal');
                                
                                const title = titleElement ? titleElement.innerText.trim() : null;
                                
                                // Skip if no title found
                                if (!title) continue;
                                
                                // Get product URL
                                const linkElement = result.querySelector('h2 .a-link-normal') || 
                                                  result.querySelector('.a-link-normal');
                                                  
                                const productUrl = linkElement && linkElement.href ? 
                                                 linkElement.href : null;
                                
                                // Skip if no URL found
                                if (!productUrl) continue;
                                
                                // Get price - try multiple price selectors
                                let price = null;
                                let priceText = null;
                                
                                const priceSelectors = [
                                    '.a-price .a-offscreen',
                                    '.a-price',
                                    '.a-color-price',
                                    '.a-price-whole'
                                ];
                                
                                for (const priceSelector of priceSelectors) {
                                    const priceElement = result.querySelector(priceSelector);
                                    if (priceElement) {
                                        priceText = priceElement.innerText.trim();
                                        if (priceText && priceText.includes('$')) {
                                            // Extract numeric price
                                            const priceMatch = priceText.match(/\$?([\d,]+\.?\d*)/);
                                            if (priceMatch) {
                                                price = parseFloat(priceMatch[1].replace(',', ''));
                                                break;
                                            }
                                        }
                                    }
                                }
                                
                                // Get rating
                                const ratingElement = result.querySelector('.a-icon-star-small') || 
                                                    result.querySelector('.a-icon-star');
                                                    
                                let rating = ratingElement ? ratingElement.innerText.trim() : null;
                                
                                // Get review count
                                const reviewElement = result.querySelector('.a-size-small .a-link-normal');
                                const reviewCount = reviewElement ? reviewElement.innerText.trim() : null;
                                
                                // Only add if we have at least a title and URL
                                if (title && productUrl) {
                                    results.push({
                                        title,
                                        price,
                                        price_text: priceText,
                                        url: productUrl,
                                        rating,
                                        review_count: reviewCount,
                                        source: 'amazon',
                                        availability: 'In Stock' // Assuming search results are available
                                    });
                                    
                                    processedCount++;
                                }
                            } catch (err) {
                                console.error("Error processing search result:", err);
                            }
                        }
                        
                        return results;
                    }
                """)
                
                # Take screenshot for debugging if no results
                if not product_data or len(product_data) == 0:
                    await page.screenshot(path="/tmp/amazon_search_results.png")
                    logger.warning("No search results found in Amazon search page")
                    return {
                        "status": "error",
                        "message": "No search results found on Amazon",
                        "source": "amazon"
                    }
                
                # Process the first valid result
                for result in product_data:
                    if result.get("title") and result.get("url"):
                        result["status"] = "success"
                        logger.info(f"Found Amazon alternative: {result.get('title')}")
                        return result
                
                return {
                    "status": "error",
                    "message": "No valid product found in Amazon search results",
                    "source": "amazon"
                }
                
            except Exception as e:
                logger.error(f"Error searching Amazon: {str(e)}")
                try:
                    await page.screenshot(path="/tmp/amazon_search_error.png")
                except:
                    pass
                    
                return {
                    "status": "error",
                    "message": f"Failed to search Amazon: {str(e)}",
                    "source": "amazon"
                }
            finally:
                await context.close()
                await browser.close()

    async def get_amazon_product_price(self, url: str) -> Optional[float]:
        """
        Special method focused solely on extracting the price from an Amazon product page.
        Optimized for reliability and speed in price extraction.
        
        Args:
            url: Amazon product URL
            
        Returns:
            Price as float or None if price couldn't be extracted
        """
        logger.info(f"Attempting focused price extraction for Amazon product: {url}")
        
        # First, try to extract ASIN for potential API lookup
        asin = self._extract_asin_from_url(url)
        if asin:
            logger.info(f"Extracted ASIN: {asin}")
            
            # Try Rainforest API if available (most reliable source)
            if self.use_rainforest:
                try:
                    product_data = await self._get_amazon_data_from_api(asin)
                    if product_data and product_data.get('price', {}).get('value'):
                        price = product_data.get('price', {}).get('value')
                        logger.info(f"Successfully extracted price from API: ${price}")
                        return price
                except Exception as e:
                    logger.warning(f"API price extraction failed: {e}")
        
        # If API fails or isn't available, try direct browser scraping with focused selectors
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                
                # Use a stealthy context for better success rate
                context = await browser.new_context(
                    user_agent=random.choice(self.desktop_agents),
                    viewport={"width": 1280, "height": 800}
                )
                
                # Add stealth script
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                """)
                
                page = await context.new_page()
                
                try:
                    # Go to the product page
                    await page.goto(url, wait_until="domcontentloaded", timeout=20000)
                    
                    # Wait for any one of the common price selectors
                    price_selectors = [
                        ".a-price .a-offscreen",
                        "#priceblock_ourprice",
                        ".a-color-price", 
                        ".priceToPay .a-offscreen",
                        "#corePrice_feature_div .a-offscreen"
                    ]
                    
                    for selector in price_selectors:
                        try:
                            await page.wait_for_selector(selector, timeout=1000)
                            logger.info(f"Found price element with selector: {selector}")
                            break
                        except:
                            continue
                    
                    # Extract price using various methods
                    price_text = await page.evaluate("""
                        () => {
                            // Try multiple price element selectors
                            const selectors = [
                                ".a-price .a-offscreen", 
                                "#priceblock_ourprice",
                                ".a-color-price",
                                ".priceToPay .a-offscreen",
                                "#corePrice_feature_div .a-offscreen",
                                ".a-price-whole",
                                ".a-section .a-price .a-offscreen",
                                "#price_inside_buybox",
                                "#buyNewSection .a-color-price",
                                "#priceblock_dealprice"
                            ];
                            
                            // Try each selector
                            for (const selector of selectors) {
                                const elements = document.querySelectorAll(selector);
                                for (const el of elements) {
                                    const text = el.textContent.trim();
                                    if (text && text.includes('$')) {
                                        return text;
                                    }
                                }
                            }
                            
                            // If no luck with selectors, search all elements with $ sign
                            const allElements = document.querySelectorAll('*');
                            for (const el of allElements) {
                                if (el.childNodes.length === 1 && 
                                    el.textContent && 
                                    el.textContent.includes('$') && 
                                    el.textContent.length < 15 &&
                                    !el.textContent.toLowerCase().includes('shipping') &&
                                    !el.textContent.toLowerCase().includes('free') &&
                                    !el.textContent.toLowerCase().includes('total')) {
                                    return el.textContent.trim();
                                }
                            }
                            
                            return null;
                        }
                    """)
                    
                    if price_text:
                        logger.info(f"Found price text: {price_text}")
                        
                        # Parse the price
                        price_match = re.search(r'\$?([\d,]+\.?\d*)', price_text)
                        if price_match:
                            price_str = price_match.group(1).replace(',', '')
                            price = float(price_str)
                            
                            # Sanity check
                            if 1 <= price <= 10000:
                                logger.info(f"Successfully extracted price: ${price}")
                                return price
                            else:
                                logger.warning(f"Price ${price} outside reasonable range, might be incorrect")
                    
                    # Take a screenshot for debugging
                    await page.screenshot(path="/tmp/amazon_price_extraction.png")
                    logger.info("Saved screenshot to /tmp/amazon_price_extraction.png for debugging")
                    
                    # Try one more desperate attempt - parse any text that looks like a price
                    try:
                        body_text = await page.evaluate('() => document.body.innerText')
                        all_prices = re.findall(r'\$\s*([\d,]+\.?\d*)', body_text)
                        
                        if all_prices:
                            # Filter to reasonable price ranges and take the median
                            valid_prices = [float(p.replace(',', '')) for p in all_prices 
                                           if 1 <= float(p.replace(',', '')) <= 10000]
                            
                            if valid_prices:
                                # Sort and take the median price
                                valid_prices.sort()
                                median_price = valid_prices[len(valid_prices) // 2]
                                logger.info(f"Extracted median price from page text: ${median_price}")
                                return median_price
                    except Exception as e:
                        logger.error(f"Error in final price extraction attempt: {e}")
                    
                    return None
                    
                except Exception as e:
                    logger.error(f"Error during price extraction: {str(e)}")
                    return None
                finally:
                    await browser.close()
        except Exception as e:
            logger.error(f"Failed to extract price with browser: {str(e)}")
            return None

    async def _get_walmart_search_result(self, search_url: str) -> Dict[str, Any]:
        """Get top search result from Walmart search page."""
        logger.info(f"Searching Walmart: {search_url}")
        
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                
                context = await browser.new_context(
                    user_agent=random.choice(self.user_agents),
                    viewport={"width": 1280, "height": 800}
                )
                
                # Add stealth script to avoid detection
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                """)
                
                page = await context.new_page()
                
                try:
                    # Navigate to search page
                    await page.goto(search_url, wait_until="domcontentloaded", timeout=20000)
                    
                    # Wait for search results to load
                    search_result_selectors = [
                        '[data-automation-id="product-results-list"] > div',
                        '[data-testid="search-results"]',
                        '.search-results-gridview-item'
                    ]
                    
                    for selector in search_result_selectors:
                        try:
                            await page.wait_for_selector(selector, timeout=3000)
                            logger.info(f"Found Walmart search results with selector: {selector}")
                            break
                        except Exception:
                            continue
                    
                    # Extract top search results
                    product_data = await page.evaluate("""
                        () => {
                            // Find product elements (vary by page layout)
                            const productSelectors = [
                                '[data-automation-id="product-results-list"] > div',
                                '[data-testid="search-results"] > div',
                                '.search-results-gridview-item'
                            ];
                            
                            let productElements = [];
                            for (const selector of productSelectors) {
                                const elements = document.querySelectorAll(selector);
                                if (elements.length > 0) {
                                    productElements = Array.from(elements);
                                    console.log(`Found ${elements.length} products with selector: ${selector}`);
                                    break;
                                }
                            }
                            
                            // Process only the top 3 products
                            const productLimit = Math.min(3, productElements.length);
                            const products = [];
                            
                            for (let i = 0; i < productLimit; i++) {
                                try {
                                    const element = productElements[i];
                                    
                                    // Find product link
                                    const linkElement = element.querySelector('a[link-identifier="linkProductTitle"], a[data-testid="product-title"], a');
                                    if (!linkElement) continue;
                                    
                                    // Get product URL and title
                                    const url = linkElement.href;
                                    const title = linkElement.textContent.trim();
                                    
                                    // Find price
                                    let price = null;
                                    let priceText = null;
                                    
                                    // Try various price selectors
                                    const priceSelectors = [
                                        '[data-automation-id="product-price"]',
                                        '[data-testid="price-wrap"] span[itemprop="price"]',
                                        '.price-characteristic',
                                        '[itemprop="price"]'
                                    ];
                                    
                                    for (const selector of priceSelectors) {
                                        const priceElement = element.querySelector(selector);
                                        if (priceElement) {
                                            priceText = priceElement.textContent.trim();
                                            const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                            if (match) {
                                                price = parseFloat(match[1].replace(',', ''));
                                                break;
                                            }
                                        }
                                    }
                                    
                                    // If still no price, look for any element with $ sign
                                    if (!price) {
                                        const allElements = element.querySelectorAll('*');
                                        for (const el of allElements) {
                                            const text = el.textContent;
                                            if (text && 
                                                text.includes('$') && 
                                                text.length < 15 &&
                                                !text.toLowerCase().includes('shipping')) {
                                                
                                                priceText = text.trim();
                                                const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                                if (match) {
                                                    price = parseFloat(match[1].replace(',', ''));
                                                    break;
                                                }
                                            }
                                        }
                                    }
                                    
                                    // Get rating if available
                                    let rating = null;
                                    const ratingElement = element.querySelector('[data-testid="rating-stars"], [itemprop="ratingValue"]');
                                    if (ratingElement) {
                                        // Try to extract numeric rating
                                        const ratingText = ratingElement.textContent.trim();
                                        const ratingMatch = ratingText.match(/(\\d+(\\.\\d+)?)/);
                                        if (ratingMatch) {
                                            rating = `${ratingMatch[1]} out of 5 stars`;
                                        } else {
                                            rating = ratingText;
                                        }
                                    }
                                    
                                    // Get image URL
                                    let imageUrl = null;
                                    const imageElement = element.querySelector('img');
                                    if (imageElement) {
                                        imageUrl = imageElement.src;
                                    }
                                    
                                    // Add product to results if we have at least title and URL
                                    if (title && url) {
                                        products.push({
                                            title,
                                            url,
                                            price,
                                            priceText: price ? (priceText || `$${price}`) : 'Price not available',
                                            rating: rating || 'No ratings',
                                            imageUrl
                                        });
                                    }
                                } catch (error) {
                                    console.error(`Error processing product element ${i}:`, error);
                                }
                            }
                            
                            return products;
                        }
                    """)
                    
                    # Take screenshot for debugging if no products found
                    if not product_data or len(product_data) == 0:
                        await page.screenshot(path="/tmp/walmart_search_error.png")
                        logger.warning("No products found in Walmart search, saved screenshot for debugging")
                        return {
                            "status": "error",
                            "message": "No products found in Walmart search results",
                            "source": "walmart"
                        }
                    
                    # Return the first valid product
                    for product in product_data:
                        if product.get("title") and product.get("url"):
                            logger.info(f"Found Walmart product: {product.get('title')[:30]}...")
                            return {
                                "status": "success",
                                "source": "walmart",
                                "url": product.get("url"),
                                "title": product.get("title"),
                                "price": product.get("price"),
                                "price_text": product.get("priceText", "Price not available"),
                                "rating": product.get("rating", "No ratings"),
                                "availability": "In Stock",  # Assume search results are in stock
                                "image_url": product.get("imageUrl")
                            }
                    
                    return {
                        "status": "error",
                        "message": "No valid products found in Walmart search results",
                        "source": "walmart"
                    }
                    
                except Exception as e:
                    logger.error(f"Error during Walmart search: {str(e)}")
                    try:
                        await page.screenshot(path="/tmp/walmart_search_error.png")
                    except:
                        pass
                    
                    return {
                        "status": "error",
                        "message": f"Failed to search Walmart: {str(e)}",
                        "source": "walmart"
                    }
                finally:
                    await browser.close()
        except Exception as e:
            logger.error(f"Failed to initialize browser for Walmart search: {str(e)}")
            return {
                "status": "error",
                "message": f"Browser initialization error: {str(e)}",
                "source": "walmart"
            }
        
    async def _get_bestbuy_search_result(self, search_url: str) -> Dict[str, Any]:
        """Get top search result from Best Buy search page."""
        logger.info(f"Searching Best Buy: {search_url}")
        
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True, timeout=10000)
                
                context = await browser.new_context(
                    user_agent=random.choice(self.user_agents),
                    viewport={"width": 1280, "height": 800}
                )
                
                # Add stealth script to avoid detection
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                """)
                
                page = await context.new_page()
                
                try:
                    # Navigate to search page
                    await page.goto(search_url, wait_until="domcontentloaded", timeout=20000)
                    
                    # Wait for search results to load
                    search_result_selectors = [
                        '.sku-item',
                        '.list-item',
                        '.product-item'
                    ]
                    
                    for selector in search_result_selectors:
                        try:
                            await page.wait_for_selector(selector, timeout=5000)
                            logger.info(f"Found Best Buy search results with selector: {selector}")
                            break
                        except Exception:
                            continue
                    
                    # Extract top search results
                    product_data = await page.evaluate("""
                        () => {
                            const productElements = document.querySelectorAll('.sku-item, .list-item, .product-item');
                            const products = [];
                            
                            // Process only the top 3 products or fewer
                            const productLimit = Math.min(3, productElements.length);
                            
                            for (let i = 0; i < productLimit; i++) {
                                try {
                                    const element = productElements[i];
                                    
                                    // Find product link and title
                                    const linkElement = element.querySelector('.sku-title a, .sku-header a, .heading a');
                                    if (!linkElement) continue;
                                    
                                    const url = linkElement.href;
                                    const title = linkElement.textContent.trim();
                                    
                                    // Find price
                                    let price = null;
                                    let priceText = null;
                                    
                                    const priceElement = element.querySelector('.priceView-customer-price span, .pricing-price, .price-block');
                                    if (priceElement) {
                                        priceText = priceElement.textContent.trim();
                                        const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                        if (match) {
                                            price = parseFloat(match[1].replace(',', ''));
                                        }
                                    }
                                    
                                    // Get rating if available
                                    let rating = null;
                                    const ratingElement = element.querySelector('.ratings-reviews');
                                    if (ratingElement) {
                                        rating = ratingElement.textContent.trim();
                                    }
                                    
                                    // Get image
                                    let imageUrl = null;
                                    const imageElement = element.querySelector('img.product-image');
                                    if (imageElement) {
                                        imageUrl = imageElement.src;
                                    }
                                    
                                    if (title && url) {
                                        products.push({
                                            title,
                                            url,
                                            price,
                                            priceText: price ? (priceText || `$${price}`) : 'Price not available',
                                            rating: rating || 'No ratings',
                                            availability: 'In Stock', // Assumption for search results
                                            imageUrl
                                        });
                                    }
                                } catch (error) {
                                    console.error('Error processing product element:', error);
                                }
                            }
                            
                            return products;
                        }
                    """)
                    
                    # Take screenshot for debugging if no products found
                    if not product_data or len(product_data) == 0:
                        await page.screenshot(path="/tmp/bestbuy_search_error.png")
                        logger.warning("No products found in Best Buy search, saved screenshot for debugging")
                        return {
                            "status": "error",
                            "message": "No products found in Best Buy search results",
                            "source": "bestbuy"
                        }
                    
                    # Return the first valid product
                    for product in product_data:
                        if product.get("title") and product.get("url"):
                            logger.info(f"Found Best Buy product: {product.get('title')[:30]}...")
                            return {
                                "status": "success",
                                "source": "bestbuy",
                                "url": product.get("url"),
                                "title": product.get("title"),
                                "price": product.get("price"),
                                "price_text": product.get("priceText", "Price not available"),
                                "rating": product.get("rating", "No ratings"),
                                "availability": "In Stock",  # Assume search results are in stock
                                "image_url": product.get("imageUrl")
                            }
                    
                    return {
                        "status": "error",
                        "message": "No valid products found in Best Buy search results",
                        "source": "bestbuy"
                    }
                    
                except Exception as e:
                    logger.error(f"Error during Best Buy search: {str(e)}")
                    await page.screenshot(path="/tmp/bestbuy_search_error.png")
                    return {
                        "status": "error",
                        "message": f"Failed to search Best Buy: {str(e)}",
                        "source": "bestbuy"
                    }
                finally:
                    await browser.close()
                    
        except Exception as e:
            logger.error(f"Error initializing browser for Best Buy search: {str(e)}")
            return {
                "status": "error",
                "message": f"Browser error: {str(e)}",
                "source": "bestbuy"
            }

    async def scrape_target(self, url: str) -> Dict[str, Any]:
        """
        Scrape product details from Target with multiple fallback techniques.
        
        Args:
            url: Target product URL
            
        Returns:
            Dict containing product details
        """
        logger.info(f"Scraping Target product: {url}")
        
        try:
            # Extract item ID from URL if possible
            item_id = None
            match = re.search(r'A-(\d+)', url)
            if match:
                item_id = match.group(1)
                logger.info(f"Extracted Target item ID: {item_id}")
            
            # Extract a basic title from the URL as fallback
            title = self._extract_title_from_url(url)
            
            # Use generic HTTP method to fetch page
            async with httpx.AsyncClient(follow_redirects=True, timeout=15.0) as client:
                headers = {
                    "User-Agent": random.choice(self.user_agents),
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                }
                
                response = await client.get(url, headers=headers)
                
                # Return basic product data
                return {
                    "status": "success",
                    "source": "target",
                    "url": url,
                    "title": title,
                    "price": None,
                    "price_text": "Price not available",
                    "rating": "No ratings",
                    "availability": "Unknown",
                    "image_url": None,
                    "item_id": item_id
                }
                
        except Exception as e:
            logger.error(f"Error scraping Target product: {str(e)}")
            return {
                "status": "error",
                "message": f"Failed to scrape Target product: {str(e)}",
                "source": "target",
                "url": url
            }
    
    async def scrape_bestbuy(self, url: str) -> Dict[str, Any]:
        """
        Scrape product details from Best Buy with multiple fallback techniques.
        
        Args:
            url: Best Buy product URL
            
        Returns:
            Dict containing product details
        """
        logger.info(f"Scraping Best Buy product with improved extractor: {url}")
        
        # Extract SKU ID from URL if possible
        sku_id = self._extract_bestbuy_sku_id(url)
        if sku_id:
            logger.info(f"Extracted Best Buy SKU ID: {sku_id}")
        
        # Set up time tracking
        start_time = time.time()
        total_timeout = 30  # 30 seconds total timeout for the entire function
        
        # Try direct HTTP request first (faster and less likely to get blocked)
        try:
            async with httpx.AsyncClient(follow_redirects=True, timeout=10.0) as client:
                headers = {
                    "User-Agent": random.choice(self.user_agents),
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                    "Accept-Language": "en-US,en;q=0.5",
                    "Cache-Control": "no-cache",
                    "Pragma": "no-cache",
                }
                
                response = await client.get(url, headers=headers)
                
                if response.status_code == 200:
                    # Parse the HTML
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # Try to extract JSON-LD data first (most reliable)
                    product_data = self._extract_bestbuy_json_ld(soup)
                    if product_data and product_data.get('price'):
                        logger.info(f"Successfully extracted Best Buy data using JSON-LD method")
                        return product_data
                    
                    # Try to extract from HTML if JSON-LD failed
                    title_element = soup.select_one('.sku-title h1, .heading-5')
                    title = title_element.text.strip() if title_element else None
                    
                    # Try multiple selectors for price
                    price = None
                    price_text = None
                    price_element = soup.select_one('.priceView-customer-price span, .priceView-hero-price')
                    
                    if price_element:
                        price_text = price_element.text.strip()
                        price_match = re.search(r'\$\s*([\d,]+\.?\d*)', price_text)
                        if price_match:
                            price = float(price_match.group(1).replace(',', ''))
                    
                    # Extract rating
                    rating = None
                    rating_element = soup.select_one('.customer-rating .c-ratings-reviews-score')
                    if rating_element:
                        rating = rating_element.text.strip()
                        rating_match = re.search(r'([\d\.]+)', rating)
                        if rating_match:
                            rating = f"{rating_match.group(1)} out of 5 stars"
                    
                    # Extract availability
                    availability = "Unknown"
                    available_element = soup.select_one('.fulfillment-add-to-cart-button button')
                    if available_element and not 'disabled' in available_element.attrs:
                        availability = "In Stock"
                    else:
                        out_of_stock = soup.select_one('.fulfillment-shipping-fulfillment-store-detail, .oos-col')
                        if out_of_stock and "not available" in out_of_stock.text.lower():
                            availability = "Out of Stock"
                    
                    # Extract image URL
                    image_url = None
                    image_element = soup.select_one('.primary-image, .carousel-main-image img')
                    if image_element and image_element.has_attr('src'):
                        image_url = image_element['src']
                    
                    if title and (price or price_text):
                        logger.info(f"Successfully extracted Best Buy data using direct HTTP method")
                        http_time = time.time() - start_time
                        logger.info(f"HTTP extraction completed in {http_time:.2f}s")
                        
                        return {
                            "status": "success",
                            "source": "bestbuy",
                            "url": url,
                            "title": title,
                            "price": price,
                            "price_text": price_text or (f"${price}" if price else "Price not available"),
                            "rating": rating or "No ratings",
                            "availability": availability,
                            "image_url": image_url,
                            "sku_id": sku_id,
                            "extracted_method": "http_request"
                        }
        except Exception as e:
            logger.warning(f"HTTP request approach failed for Best Buy: {str(e)}")
        
        # Fall back to browser approach with improved extraction
        try:
            # Set strict timeouts to prevent hanging
            navigation_timeout = 15000  # 15 seconds
            element_timeout = 5000      # 5 seconds
            evaluation_timeout = 10000  # 10 seconds
            
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                
                context = await browser.new_context(
                    user_agent=random.choice(self.user_agents),
                    viewport={"width": 1280, "height": 800}
                )
                
                # Add stealth script to avoid detection
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                """)
                
                page = await context.new_page()
                
                try:
                    # Navigate to product page
                    await page.goto(url, wait_until="domcontentloaded", timeout=20000)
                    
                    # Take screenshot for debugging purposes
                    screenshot_path = f"/tmp/bestbuy_{int(time.time())}.png"
                    await page.screenshot(path=screenshot_path)
                    
                    # Wait for price element to appear
                    price_selectors = [
                        '.priceView-customer-price', 
                        '.priceView-hero-price',
                        '.price-box'
                    ]
                    
                    price_found = False
                    for selector in price_selectors:
                        try:
                            await page.wait_for_selector(selector, timeout=3000)
                            logger.info(f"Found Best Buy price element with selector: {selector}")
                            price_found = True
                            break
                        except Exception:
                            continue
                    
                    # Extract product data using JavaScript
                    product_data = await page.evaluate("""
                        () => {
                            // Extract title
                            let title = null;
                            const titleElement = document.querySelector('.sku-title h1, .heading-5');
                            if (titleElement) {
                                title = titleElement.textContent.trim();
                            }
                            
                            // Extract price using multiple methods
                            let price = null;
                            let priceText = null;
                            
                            // Method 1: Look for standard Best Buy price display
                            const priceElement = document.querySelector(
                                '.priceView-customer-price span, .priceView-hero-price'
                            );
                            
                            if (priceElement) {
                                priceText = priceElement.textContent.trim();
                                const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                if (match) {
                                    price = parseFloat(match[1].replace(',', ''));
                                }
                            }
                            
                            // Method 2: Try structured data from schema.org
                            if (!price) {
                                const jsonLD = document.querySelector('script[type="application/ld+json"]');
                                if (jsonLD) {
                                    try {
                                        const data = JSON.parse(jsonLD.textContent);
                                        if (data.offers && data.offers.price) {
                                            price = parseFloat(data.offers.price);
                                            priceText = '$' + price.toFixed(2);
                                        } else if (Array.isArray(data) && data[0] && data[0].offers && data[0].offers.price) {
                                            price = parseFloat(data[0].offers.price);
                                            priceText = '$' + price.toFixed(2);
                                        }
                                    } catch (e) {
                                        console.error("Error parsing JSON-LD:", e);
                                    }
                                }
                            }
                            
                            // Method 3: Generic price extraction from any element with $ sign
                            if (!price) {
                                const allElements = document.querySelectorAll('*');
                                for (const el of allElements) {
                                    if (el.childNodes.length === 1 && 
                                        el.textContent && 
                                        el.textContent.includes('$') && 
                                        el.textContent.length < 15 &&
                                        !el.textContent.toLowerCase().includes('shipping') &&
                                        !el.textContent.toLowerCase().includes('save')) {
                                        
                                        priceText = el.textContent.trim();
                                        const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                        if (match) {
                                            price = parseFloat(match[1].replace(',', ''));
                                            break;
                                        }
                                    }
                                }
                            }
                            
                            // Extract rating
                            let rating = null;
                            const ratingElement = document.querySelector('.customer-rating .c-ratings-reviews-score');
                            if (ratingElement) {
                                rating = ratingElement.textContent.trim();
                                // Try to extract just the number from the rating
                                const ratingMatch = rating.match(/(\\d+\\.?\\d*)/);
                                if (ratingMatch) {
                                    rating = ratingMatch[1] + " out of 5 stars";
                                }
                            }
                            
                            // Extract availability
                            let availability = null;
                            const availabilityElement = document.querySelector('.fulfillment-add-to-cart-button button');
                            if (availabilityElement) {
                                availability = "In Stock";
                            } else {
                                const outOfStockElement = document.querySelector('.oos-col');
                                if (outOfStockElement) {
                                    availability = "Out of Stock";
                                }
                            }
                            
                            // Extract image URL
                            let imageUrl = null;
                            const imageElement = document.querySelector('.primary-image, .carousel-main-image img');
                            if (imageElement && imageElement.src) {
                                imageUrl = imageElement.src;
                            }
                            
                            return {
                                title,
                                price,
                                priceText,
                                rating,
                                availability,
                                imageUrl,
                                pageTitle: document.title
                            };
                        }
                    """)
                    
                    # Create final result
                    title = product_data.get('title')
                    price = product_data.get('price')
                    price_text = product_data.get('priceText')
                    rating = product_data.get('rating')
                    availability = product_data.get('availability')
                    image_url = product_data.get('imageUrl')
                    
                    # Last attempt to extract prices if needed
                    if price is None:
                        try:
                            # Try to find any text that looks like a price
                            body_text = await page.evaluate('() => document.body.innerText')
                            price_matches = re.findall(r'\$\s*([\d,]+\.?\d*)', body_text)
                            
                            if price_matches:
                                # Filter to reasonable price ranges
                                valid_prices = [float(p.replace(',', '')) for p in price_matches 
                                              if 1 <= float(p.replace(',', '')) <= 10000]
                                
                                if valid_prices:
                                    # Sort and take the median price
                                    valid_prices.sort()
                                    price = valid_prices[len(valid_prices) // 2]
                                    price_text = f"${price:.2f}"
                                    logger.info(f"Extracted median price from Best Buy page text: ${price}")
                        except Exception as e:
                            logger.error(f"Error in final Best Buy price extraction attempt: {e}")
                    
                    return {
                        "status": "success",
                        "source": "bestbuy",
                        "url": url,
                        "title": title or "Unknown Best Buy Product",
                        "price": price,
                        "price_text": price_text or ("$" + str(price) if price else "Price not available"),
                        "rating": rating or "No ratings",
                        "availability": availability or "Unknown",
                        "image_url": image_url,
                        "screenshot": screenshot_path,
                        "extracted_method": "browser"
                    }
                
                except Exception as e:
                    logger.error(f"Error scraping Best Buy product: {str(e)}")
                    # Extract title from URL as fallback
                    title = self._extract_title_from_bestbuy_url(url)
                    return {
                        "status": "error",
                        "message": f"Failed to scrape Best Buy product: {str(e)}",
                        "source": "bestbuy",
                        "url": url,
                        "title": title or "Unknown Best Buy Product"
                    }
                finally:
                    await browser.close()
                    
        except Exception as e:
            logger.error(f"Error initializing browser for Best Buy search: {str(e)}")
            return {
                "status": "error",
                "message": f"Browser error: {str(e)}",
                "source": "bestbuy"
            }

    def _extract_bestbuy_json_ld(self, soup: BeautifulSoup) -> Optional[Dict[str, Any]]:
        """Extract structured data from Best Buy product page."""
        try:
            json_ld_scripts = soup.select('script[type="application/ld+json"]')
            for script in json_ld_scripts:
                try:
                    data = json.loads(script.string)
                    
                    # Handle different schema formats
                    if isinstance(data, list):
                        data = data[0]
                    
                    if data.get("@type") == "Product":
                        # Extract product details
                        title = data.get("name")
                        
                        # Extract price
                        price = None
                        price_text = None
                        if "offers" in data:
                            offers = data["offers"]
                            if isinstance(offers, dict):
                                price = offers.get("price")
                                if price:
                                    price = float(price)
                                    price_text = f"${price}"
                            elif isinstance(offers, list) and len(offers) > 0:
                                offer = offers[0]
                                price = offer.get("price")
                                if price:
                                    price = float(price)
                                    price_text = f"${price}"
                        
                        # Extract rating
                        rating = None
                        if "aggregateRating" in data:
                            rating_value = data["aggregateRating"].get("ratingValue")
                            if rating_value:
                                rating = f"{rating_value} out of 5 stars"
                        
                        # Extract image
                        image_url = None
                        if "image" in data:
                            image = data["image"]
                            if isinstance(image, list) and len(image) > 0:
                                image_url = image[0]
                            else:
                                image_url = image
                        
                        # Create result
                        if title and price is not None:
                            return {
                                "status": "success",
                                "source": "bestbuy",
                                "title": title,
                                "price": price,
                                "price_text": price_text,
                                "rating": rating or "No ratings",
                                "availability": "In Stock", # Default assumption from JSON-LD
                                "image_url": image_url,
                                "extracted_method": "json_ld"
                            }
                except Exception as e:
                    logger.warning(f"Error parsing Best Buy JSON-LD data: {e}")
                    continue
            
            return None
        except Exception as e:
            logger.error(f"Error extracting Best Buy JSON-LD: {e}")
            return None

    def cleanup(self):
        """Clean up temporary files and data."""
        try:
            import shutil
            shutil.rmtree(self.temp_dir, ignore_errors=True)
            logger.info(f"Cleaned up temporary directory: {self.temp_dir}")
        except Exception as e:
            logger.error(f"Error cleaning up temporary files: {str(e)}")

    def _extract_target_item_id(self, url: str) -> Optional[str]:
        """Extract item ID from Target URL."""
        try:
            # Try to find item ID in the URL query parameters
            parsed_url = urlparse(url)
            path = parsed_url.path
            
            # Format like /p/product-name/-/A-12345678
            match = re.search(r'A-(\d+)', path)
            if match:
                return match.group(1)
            
            # Also check query parameters
            query_params = parse_qs(parsed_url.query)
            if 'preselect' in query_params:
                return query_params['preselect'][0]
                
            return None
        except Exception:
            return None
    
    def _extract_title_from_target_url(self, url: str) -> Optional[str]:
        """Extract product title from Target URL."""
        try:
            # Target URLs typically have the product name in the path
            # Format: /p/product-name/-/A-12345678
            parsed_url = urlparse(url)
            path = parsed_url.path
            
            # Extract product name segment
            match = re.search(r'/p/([^/]+)', path)
            if match:
                product_name = match.group(1)
                # Clean up the product name
                product_name = product_name.replace('-', ' ')
                return product_name.title()
                
            return None
        except Exception:
            return None


class PriceScraper:
    def __init__(self):
        """Initialize the price scraper."""
        # Initialize user agent rotation
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15"
        ]
        
        self.headers = {
            "User-Agent": random.choice(self.user_agents),
            "Accept-Language": "en-US,en;q=0.9",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "sec-ch-ua": '"Chromium";v="124", "Google Chrome";v="124", "Not-A.Brand";v="99"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "document",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "none",
            "sec-fetch-user": "?1",
            "upgrade-insecure-requests": "1",
            "Cache-Control": "max-age=0",
            "Connection": "keep-alive",
            "DNT": "1",
            "Pragma": "no-cache"
        }
        self.timeout = 20.0
        
        # Initialize proxy settings
        self.proxy_username = os.getenv("PROXY_USERNAME")
        self.proxy_password = os.getenv("PROXY_PASSWORD")
        self.proxy_host = os.getenv("PROXY_HOST")
        self.proxy_port = os.getenv("PROXY_PORT")
        
        # Initialize stealth scraper
        self.stealth_scraper = StealthScraper()
        
        # Save cookies between sessions
        self.cookies_dir = os.path.join(tempfile.gettempdir(), "ecommerce_cookies")
        os.makedirs(self.cookies_dir, exist_ok=True)
        
        if not all([self.proxy_username, self.proxy_password, self.proxy_host, self.proxy_port]):
            logger.warning("Proxy credentials not fully configured. Some features may be limited.")

    async def _get_proxy_url(self) -> str:
        """Get the proxy URL with authentication."""
        if all([self.proxy_username, self.proxy_password, self.proxy_host, self.proxy_port]):
            return f"http://{self.proxy_username}:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}"
        return None

    async def get_product_details(self, url: str) -> Dict[str, Any]:
        """
        Fetch product details from the given URL using the most reliable method.
        This updated version uses API-first approach with browser fallback.
        """
        parsed_url = urlparse(url)
        domain = parsed_url.netloc.lower()
        
        # Force proper source identification
        source = "unknown"
        if "amazon" in domain or "amazon" in url.lower() or "a.co" in domain:
            source = "amazon"
        elif "target" in domain or "target.com" in url.lower():
            source = "target"
        elif "bestbuy" in domain or "best-buy" in url.lower() or "bestbuy" in url.lower():
            source = "bestbuy"
        elif "walmart" in domain or "walmart" in url.lower():
            source = "walmart"
        elif "costco" in domain or "costco.com" in url.lower():
            source = "costco"
            
        logger.info(f"IDENTIFIED SOURCE AS: {source} FOR URL: {url}")
        
        try:
            # Fix source identification by checking domains more robustly
            if source == "amazon":
                # Use the new stealth strategy and ensure source is set properly
                result = await self.stealth_scraper.get_amazon_product_data(url)
                # Fix source if needed (sometimes it might come back as 'www' or other value)
                if result:
                    if result.get("status") == "success":
                        result["source"] = "amazon"  # FORCE source to be amazon
                    return result
            elif source == "target":
                # Call the Target-specific scraper
                result = await self.scrape_target(url)
                if result.get("status") == "success":
                    result["source"] = "target"
                return result
            elif source == "bestbuy":
                # Call the Best Buy-specific scraper
                result = await self.scrape_bestbuy(url)
                if result.get("status") == "success":
                    result["source"] = "bestbuy"
                return result
            elif source == "walmart":
                # Call the Walmart-specific scraper
                result = await self.scrape_walmart(url)
                if result.get("status") == "success":
                    result["source"] = "walmart"
                return result
            else:
                # For unknown sources, make best effort to extract info
                # Try to determine the most likely source based on URL patterns
                if "amazon" in url.lower():
                    source = "amazon"
                    result = await self.stealth_scraper.get_amazon_product_data(url)
                    if result.get("status") == "success":
                        result["source"] = "amazon"  # FORCE source to be amazon
                    return result
                elif "target" in url.lower():
                    source = "target"
                    return await self.scrape_target(url)
                elif "bestbuy" in url.lower() or "best-buy" in url.lower():
                    source = "bestbuy"
                    return await self.scrape_bestbuy(url)
                elif "walmart" in url.lower():
                    source = "walmart"
                    return await self.scrape_walmart(url)
                
                return {
                    "status": "error",
                    "message": f"Unsupported website: {domain}",
                    "source": source,
                    "url": url
                }
        except Exception as e:
            logger.error(f"Error scraping {url}: {str(e)}")
            # Try to determine source even in case of error
            return {
                "status": "error",
                "message": f"Failed to scrape product: {str(e)}",
                "source": source,  # Use the source we determined earlier
                "url": url
            }

    def _extract_title_from_url(self, url: str) -> str:
        """Extract a reasonable product title from the URL."""
        try:
            # Extract from path
            path = urlparse(url).path
            
            # Remove file extensions and trailing slashes
            path = re.sub(r'\.\w+$', '', path).rstrip('/')
            
            # Split by slashes and get the last meaningful segment
            segments = [s for s in path.split('/') if s and len(s) > 1]
            
            if segments:
                # Try to find a segment that looks like a product title
                # Usually it's the last segment before query parameters
                raw_title = segments[-1]
                
                # Replace hyphens and underscores with spaces
                title = re.sub(r'[-_]', ' ', raw_title)
                
                # Capitalize words
                title = ' '.join(word.capitalize() for word in title.split())
                
                # Clean up common patterns
                title = re.sub(r'\b[A-Z0-9]{10,}\b', '', title)  # Remove ASIN-like strings
                title = re.sub(r'\s+', ' ', title).strip()  # Clean up whitespace
                
                if len(title) > 5:  # If we have something meaningful
                    return title
            
            # Fallback: Look for product name in query parameters
            query = urlparse(url).query
            query_params = parse_qs(query)
            
            for param_name in ['title', 'name', 'product', 'item']:
                if param_name in query_params:
                    return query_params[param_name][0]
            
            # Last resort
            for segment in segments:
                if len(segment) > 5 and not segment.isdigit():
                    return re.sub(r'[-_]', ' ', segment).title()
                    
            # Ultimate fallback
            return "Unknown Product"
            
        except Exception as e:
            logger.error(f"Error extracting title from URL: {str(e)}")
            return "Unknown Product"

    async def find_alternatives(self, product_details: Dict[str, Any], max_results: int = 3) -> List[Dict[str, Any]]:
        """
        Find alternative products on other sites based on the provided product details.
        Uses multiple search strategies to find the most relevant alternatives.
        
        Now includes specialized handlers for specific retailers.
        """
        if product_details.get("status") != "success":
            return []
        
        # Ensure source is properly set - fallback to extraction from URL if needed
        original_source = product_details.get('source', '').lower()
        url = product_details.get('url', '')
        
        # CRITICAL FIX: If source is "www" and URL contains amazon, set source to amazon
        if original_source == 'www' and 'amazon' in url.lower():
            logger.info(f"Fixing source from 'www' to 'amazon' for alternatives search: {url}")
            product_details['source'] = 'amazon'
            original_source = 'amazon'
        
        # Log the search attempt for better debugging
        logger.info(f"Searching for alternatives for product from {product_details.get('source', 'unknown')} with title: {product_details.get('title', 'Unknown')}")
        
        # If we don't have a price, try to get it from the price_text
        if product_details.get('price') is None and product_details.get('price_text'):
            try:
                price_text = product_details.get('price_text', '')
                price_match = re.search(r'\$?([\d,]+\.?\d*)', price_text)
                if price_match:
                    price_str = price_match.group(1).replace(',', '')
                    price = float(price_str)
                    # Add it to the product details
                    product_details['price'] = price
                    logger.info(f"Extracted price ${price} from price_text '{price_text}' for alternatives search")
            except Exception as e:
                logger.error(f"Failed to extract price from price_text: {e}")
        
        # Set a global timeout for the entire alternatives search process
        start_time = time.time()
        global_timeout = 25.0  # 25 seconds maximum for the entire alternatives search
        
        # Store alternatives from all strategies
        all_alternatives = []
        
        # Special retailer-specific handling
        # This helps us handle specific retailers with specialized methods
        if original_source.lower() == 'walmart':
            try:
                # Use our specialized Walmart alternatives finder
                walmart_timeout = 20.0
                
                logger.info(f"Using specialized Walmart alternatives finder with {walmart_timeout}s timeout")
                
                # Create a task for the Walmart alternatives
                walmart_task = asyncio.create_task(
                    self._find_walmart_alternatives(product_details, max_results)
                )
                
                # Create a timeout task
                timeout_task = asyncio.create_task(asyncio.sleep(walmart_timeout))
                
                # Wait for either task to complete
                done, pending = await asyncio.wait(
                    {walmart_task, timeout_task},
                    return_when=asyncio.FIRST_COMPLETED
                )
                
                # Cancel pending tasks
                for task in pending:
                    task.cancel()
                
                # If the Walmart alternatives task completed, process results
                if walmart_task in done:
                    walmart_alternatives = await walmart_task
                    if walmart_alternatives:
                        logger.info(f"Specialized Walmart finder found {len(walmart_alternatives)} alternatives")
                        all_alternatives.extend(walmart_alternatives)
                else:
                    logger.warning(f"Specialized Walmart finder timed out after {walmart_timeout}s")
            except Exception as e:
                logger.error(f"Error using specialized Walmart alternatives finder: {e}")
        
        # If we still don't have enough alternatives, try the standard methods
        if len(all_alternatives) < max_results and (time.time() - start_time) < global_timeout:
            source = product_details.get('source', 'unknown').lower()
            title = product_details.get('title', 'Unknown Product')
            current_price = product_details.get('price')
            current_rating = self._extract_rating_value(product_details.get('rating', '0'))
            
            # Create multiple search query strategies
            search_strategies = []
            
            # Strategy 1: Generate search queries from product title and details
            title_queries = self._generate_title_search_queries(title)
            search_strategies.append(("Title-based", title_queries))
            
            # Strategy 2: Use product category + key attributes if identified
            category = self._identify_product_category(title, url)
            attribute_queries = self._generate_attribute_search_queries(title, category)
            search_strategies.append(("Attribute-based", attribute_queries))
            
            # Strategy 3: Use brand + key model words
            brand_queries = self._generate_brand_search_queries(title)
            search_strategies.append(("Brand-based", brand_queries))
            
            # Create search URLs for different stores
            stores = {
                "amazon": lambda q: f"https://www.amazon.com/s?k={q}",
                "walmart": lambda q: f"https://www.walmart.com/search/?query={q}",
                "bestbuy": lambda q: f"https://www.bestbuy.com/site/searchpage.jsp?st={q}",
                "target": lambda q: f"https://www.target.com/s?searchTerm={q}",
                "costco": lambda q: f"https://www.costco.com/CatalogSearch?keyword={q}"
            }
            
            # Keep track of alternatives
            processed_stores = set()
            
            # Function to deduplicate alternatives
            def is_duplicate(alt):
                for existing_alt in all_alternatives:
                    if alt.get('url') == existing_alt.get('url'):
                        return True
                    if alt.get('title') and existing_alt.get('title') and alt.get('title') == existing_alt.get('title'):
                        return True
                return False
            
            # For each store (except the source store)
            for store_name, search_url_func in stores.items():
                # Skip if we've already processed this store or it's the original source
                if store_name == source or store_name in processed_stores:
                    continue
                    
                # Skip if we've reached max results
                if len(all_alternatives) >= max_results:
                    break
                    
                # Skip if we've exceeded our time limit
                if (time.time() - start_time) >= global_timeout:
                    logger.warning(f"Global timeout reached after {global_timeout}s")
                    break
                
                logger.info(f"Looking for alternatives at {store_name} for {title}")
                alt_product = None
                
                # Try each search strategy until one finds a result
                for strategy_name, queries in search_strategies:
                    if alt_product and alt_product.get("status") == "success":
                        break
                        
                    # Skip if we've exceeded our time limit for this strategy
                    if (time.time() - start_time) >= global_timeout:
                        break
                        
                    logger.info(f"Trying {strategy_name} search strategy for {store_name}")
                    
                    for query in queries:
                        # Skip if we've reached max results
                        if len(all_alternatives) >= max_results:
                            break
                            
                        # Skip if we've exceeded our time limit for this query
                        if (time.time() - start_time) >= global_timeout:
                            break
                            
                        if alt_product and alt_product.get("status") == "success":
                            break
                            
                        search_url = search_url_func(query)
                        logger.info(f"Searching {store_name} with query: {query}")
                        
                        try:
                            # Use a shorter timeout for each individual search
                            search_timeout = 7.0  # 7 seconds per search
                            
                            # Create a task for the search
                            search_task = asyncio.create_task(
                                self._get_top_search_result(store_name, search_url)
                            )
                            
                            # Create a timeout task
                            timeout_task = asyncio.create_task(asyncio.sleep(search_timeout))
                            
                            # Wait for either search to complete or timeout
                            done, pending = await asyncio.wait(
                                {search_task, timeout_task},
                                return_when=asyncio.FIRST_COMPLETED
                            )
                            
                            # Cancel pending tasks
                            for task in pending:
                                task.cancel()
                            
                            # If the search task completed, process results
                            if search_task in done:
                                alt_product = await search_task
                                
                                if alt_product and alt_product.get("status") == "success":
                                    logger.info(f"Found match at {store_name} using query: {query}")
                                    break
                            else:
                                # Search timed out
                                logger.warning(f"Search timed out for {store_name} with query: {query}")
                        except Exception as e:
                            logger.error(f"Error searching {store_name} with query {query}: {e}")
                
                # If we found an alternative for this store, process it
                if alt_product and alt_product.get("status") == "success":
                    # Skip if it's a duplicate of an existing alternative
                    if is_duplicate(alt_product):
                        logger.info(f"Skipping duplicate alternative from {store_name}")
                        continue
                        
                    # Mark this store as processed
                    processed_stores.add(store_name)
                    
                    # Combine data from multiple sources if needed
                    self._enrich_product_data(alt_product)
                    
                    alt_price = alt_product.get("price")
                    
                    # Apply sanity check for alternative prices
                    if alt_price is not None:
                        if alt_price > 10000 or alt_price < 1:
                            logger.warning(f"Possible incorrect alternative price detected: ${alt_price} for {alt_product.get('title')}")
                            if any(keyword in alt_product.get('title', '').lower() for keyword in ['shoe', 'trainer', 'sneaker']):
                                logger.info(f"Alternative appears to be footwear which typically costs $30-$200, not ${alt_price}")
                                # Don't add this alternative with suspicious price
                                continue

                    alt_rating_value = self._extract_rating_value(alt_product.get("rating", "0"))
                    
                    # Calculate price difference percentage if both prices exist
                    price_reason = ""
                    if current_price and alt_price:
                        price_diff_pct = ((current_price - alt_price) / current_price) * 100
                        if price_diff_pct > 3:  # More than 3% cheaper
                            price_reason = f"{abs(round(price_diff_pct))}% cheaper than {source.capitalize()}"
                        elif price_diff_pct < -3:  # More than 3% more expensive
                            price_reason = f"{abs(round(price_diff_pct))}% more expensive than {source.capitalize()}"
                        else:
                            price_reason = f"Similar price to {source.capitalize()}"
                    
                    # Create combined reason text based on real data
                    reasons = []
                    if price_reason:
                        reasons.append(price_reason)
                    if alt_rating_value > current_rating + 0.3:
                        reasons.append(f"Higher customer rating ({alt_rating_value:.1f} vs {current_rating:.1f})")
                    elif current_rating > alt_rating_value + 0.3:
                        reasons.append(f"Lower customer rating ({alt_rating_value:.1f} vs {current_rating:.1f})")
                    
                    if alt_product.get("availability") and "in stock" in alt_product.get("availability").lower():
                        reasons.append("In stock and ready to ship")
                    
                    # Join all reasons
                    reason = " | ".join(reasons) if reasons else "Alternative option"
                    
                    # Calculate holistic score based on real data
                    # Price score (0-50 points)
                    price_score = 25  # Default neutral
                    if current_price and alt_price:
                        # Lower price is better
                        price_diff_pct = ((current_price - alt_price) / current_price) * 100
                        price_score = min(50, max(0, 25 + price_diff_pct))
                    
                    # Rating score (0-30 points)
                    rating_score = (alt_rating_value / 5.0) * 30
                    
                    # Reviews volume score (0-10 points)
                    review_count_text = alt_product.get("review_count", "0")
                    try:
                        review_count = int(re.search(r'\d+', review_count_text).group()) if isinstance(review_count_text, str) else 0
                    except (AttributeError, ValueError):
                        review_count = 0
                    
                    review_volume_score = min(10, (review_count / 1000) * 10) if review_count else 0
                    
                    # Availability score (0-10 points)
                    availability = alt_product.get("availability", "Unknown")
                    availability_score = 10 if availability and "in stock" in availability.lower() else 5
                    
                    # Calculate total holistic score
                    holistic_score = price_score + rating_score + review_volume_score + availability_score
                    
                    # Determine if it's a better deal overall based on holistic score
                    is_better_deal = holistic_score > 50
                    
                    # Add to alternatives
                    alternative_data = {
                        "source": store_name,
                        "title": alt_product.get("title", "Unknown Product"),
                        "price": alt_price,
                        "url": alt_product.get("url", search_url),
                        "is_better_deal": is_better_deal,
                        "reason": reason,
                        "rating": alt_product.get("rating", "No ratings"),
                        "review_count": review_count,
                        "availability": alt_product.get("availability", "Unknown"),
                        "holistic_score": round(holistic_score, 1)
                    }
                    
                    all_alternatives.append(alternative_data)
                    logger.info(f"Added alternative from {store_name}: {alt_product.get('title')} for ${alt_price}")
        
        # Return all alternatives we've found, up to max_results
        if all_alternatives:
            # Sort by holistic score (best first)
            all_alternatives.sort(key=lambda x: x.get("holistic_score", 0), reverse=True)
            logger.info(f"Total alternatives found: {len(all_alternatives)}")
        else:
            logger.warning("No alternatives found through any strategy")
        
        return all_alternatives[:max_results]

    def _generate_title_search_queries(self, title: str) -> List[str]:
        """Generate search queries based on product title."""
        queries = []
        
        # Clean title for better search results
        search_title = title
        
        # Strategy 1: First few important words (standard)
        important_words = ' '.join(search_title.split()[:6])
        queries.append(important_words.replace(" ", "+"))
        
        # Strategy 2: Just use the essential words (first 3-4)
        essential_words = ' '.join(search_title.split()[:4])
        queries.append(essential_words.replace(" ", "+"))
        
        # Strategy 3: Exclude brand if it's the first word
        parts = search_title.split(" ", 1)
        if len(parts) > 1 and len(parts[0]) < 15:  # First word could be brand
            no_brand = parts[1]  # Use remainder for search
            queries.append(no_brand.replace(" ", "+"))
        
        return queries
    
    def _identify_product_category(self, title: str, url: str) -> str:
        """Identify the product category based on title and URL."""
        title_lower = title.lower()
        url_lower = url.lower()
        
        # Check for common product categories
        if any(word in title_lower or word in url_lower for word in ['shoe', 'trainer', 'sneaker', 'footwear']):
            return "shoes"
        elif any(word in title_lower or word in url_lower for word in ['laptop', 'notebook', 'computer']):
            return "computers"
        elif any(word in title_lower or word in url_lower for word in ['phone', 'smartphone', 'cell']):
            return "phones"
        elif any(word in title_lower or word in url_lower for word in ['tv', 'television', 'monitor', 'screen']):
            return "tvs"
        elif any(word in title_lower or word in url_lower for word in ['watch', 'smartwatch']):
            return "watches"
        elif any(word in title_lower or word in url_lower for word in ['headphone', 'earbud', 'earphone']):
            return "audio"
        elif any(word in title_lower or word in url_lower for word in ['camera', 'dslr', 'mirrorless']):
            return "cameras"
        else:
            return "general"
            
    def _generate_attribute_search_queries(self, title: str, category: str) -> List[str]:
        """Generate search queries based on product attributes for the given category."""
        queries = []
        title_lower = title.lower()
        
        # Extract potential brand name (usually first word)
        parts = title.split(" ", 1)
        brand = parts[0] if len(parts) > 1 else ""
        
        # Extract color if present
        color_match = re.search(r'(black|white|red|blue|green|yellow|gray|grey|brown|purple|pink|orange|gold|silver)', 
                               title_lower)
        color = color_match.group(1) if color_match else None
        
        # Extract size if present
        size_match = re.search(r'size\s+(\w+)', title_lower)
        size = size_match.group(1) if size_match else None
        
        # Extract model number if present
        model_match = re.search(r'model\s+([A-Za-z0-9\-]+)', title_lower)
        model = model_match.group(1) if model_match else None
        
        # Create category-specific queries
        if category == "shoes":
            # Shoes typically search by brand + type + gender/size
            if brand:
                queries.append(f"{brand}+{category}")
                if color:
                    queries.append(f"{brand}+{color}+{category}")
                if "women" in title_lower:
                    queries.append(f"{brand}+women+{category}")
                elif "men" in title_lower:
                    queries.append(f"{brand}+men+{category}")
        
        elif category == "computers":
            # Computer searches often include specs
            if brand:
                queries.append(f"{brand}+laptop")
                # Look for screen size
                screen_match = re.search(r'(\d+(\.\d+)?)\s*inch', title_lower)
                if screen_match:
                    screen_size = screen_match.group(1)
                    queries.append(f"{brand}+{screen_size}+inch+laptop")
        
        elif category == "phones":
            # Phone searches typically include model names/numbers
            if brand:
                queries.append(f"{brand}+phone")
                # Extract model if it exists
                if model:
                    queries.append(f"{brand}+{model}+phone")
                elif "pro" in title_lower:
                    queries.append(f"{brand}+pro+phone")
        
        # Add general attribute combinations for any category
        if brand and color:
            queries.append(f"{brand}+{color}")
        if brand and model:
            queries.append(f"{brand}+{model}")
        
        return queries
    
    def _generate_brand_search_queries(self, title: str) -> List[str]:
        """Generate search queries focused on brand and model."""
        queries = []
        
        # Extract potential brand (first word)
        parts = title.split(" ", 1)
        if len(parts) > 1:
            brand = parts[0]
            
            # Brand + next 1-2 words (likely model)
            model_words = parts[1].split()[:2]
            if model_words:
                queries.append(f"{brand}+{'+'.join(model_words)}")
            
            # Brand + product type words
            product_types = ["shoe", "trainer", "laptop", "computer", "phone", "tv", "watch"]
            for product_type in product_types:
                if product_type in title.lower():
                    queries.append(f"{brand}+{product_type}")
        
        return queries

    def _extract_rating_value(self, rating_text: str) -> float:
        """Extract numeric rating value from rating text."""
        try:
            # Try to extract a number from text like "4.5 out of 5 stars"
            match = re.search(r'(\d+(\.\d+)?)', rating_text)
            if match:
                return float(match.group(1))
            return 0.0
        except (ValueError, TypeError, AttributeError):
            return 0.0

    async def _get_top_search_result(self, store_name: str, search_url: str) -> Dict[str, Any]:
        """Get top search result from a store's search page."""
        logger.info(f"Searching for alternatives on {store_name} at {search_url}")
        
        try:
            # Select appropriate method based on store
            if store_name == "amazon":
                return await self._get_amazon_search_result(search_url)
            elif store_name == "walmart":
                return await self._get_walmart_search_result(search_url)
            elif store_name == "bestbuy":
                return await self._get_bestbuy_search_result(search_url)
            elif store_name == "target":
                return await self._get_target_search_result(search_url)
            else:
                # Generic fallback using browser approach
                return await self._get_generic_search_result(store_name, search_url)
        except Exception as e:
            logger.error(f"Error getting search result from {store_name}: {e}")
            return {
                "status": "error",
                "message": f"Failed to find alternatives on {store_name}: {str(e)}"
            }
    
    async def _get_target_search_result(self, search_url: str) -> Dict[str, Any]:
        """Get top search result from Target search page."""
        logger.info(f"Searching Target: {search_url}")
        
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                
                context = await browser.new_context(
                    user_agent=random.choice(self.user_agents),
                    viewport={"width": 1280, "height": 800}
                )
                
                # Add stealth script to avoid detection
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                """)
                
                page = await context.new_page()
                
                try:
                    # Navigate to search page
                    await page.goto(search_url, wait_until="domcontentloaded", timeout=20000)
                    
                    # Wait for search results to load
                    search_result_selectors = [
                        '[data-test="product-grid"] > div',
                        '[data-test="product-card-default"]',
                        '.styles__StyledCol-sc-fw90uk-0'
                    ]
                    
                    for selector in search_result_selectors:
                        try:
                            await page.wait_for_selector(selector, timeout=3000)
                            logger.info(f"Found Target search results with selector: {selector}")
                            break
                        except Exception:
                            continue
                    
                    # Extract top search results
                    product_data = await page.evaluate("""
                        () => {
                            // Find product elements (vary by page layout)
                            const productSelectors = [
                                '[data-test="product-grid"] > div',
                                '[data-test="product-card-default"]',
                                '.styles__StyledCol-sc-fw90uk-0'
                            ];
                            
                            let productElements = [];
                            for (const selector of productSelectors) {
                                const elements = document.querySelectorAll(selector);
                                if (elements.length > 0) {
                                    productElements = Array.from(elements);
                                    console.log(`Found ${elements.length} products with selector: ${selector}`);
                                    break;
                                }
                            }
                            
                            // Process only the top 3 products
                            const productLimit = Math.min(3, productElements.length);
                            const products = [];
                            
                            for (let i = 0; i < productLimit; i++) {
                                try {
                                    const element = productElements[i];
                                    
                                    // Find product link
                                    const linkElement = element.querySelector('a[data-test="product-title"], a[href^="/p/"]');
                                    if (!linkElement) continue;
                                    
                                    // Get product URL and title
                                    const url = linkElement.href;
                                    const title = linkElement.textContent.trim();
                                    
                                    // Find price
                                    let price = null;
                                    let priceText = null;
                                    
                                    // Try various price selectors
                                    const priceSelectors = [
                                        '[data-test="product-price"]',
                                        '[data-component="Price"]',
                                        '.styles__CurrentPriceWrapper-sc-1irel10-2'
                                    ];
                                    
                                    for (const selector of priceSelectors) {
                                        const priceElement = element.querySelector(selector);
                                        if (priceElement) {
                                            priceText = priceElement.textContent.trim();
                                            const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                            if (match) {
                                                price = parseFloat(match[1].replace(',', ''));
                                                break;
                                            }
                                        }
                                    }
                                    
                                    // If still no price, look for any element with $ sign
                                    if (!price) {
                                        const allElements = element.querySelectorAll('*');
                                        for (const el of allElements) {
                                            const text = el.textContent;
                                            if (text && 
                                                text.includes('$') && 
                                                text.length < 15 &&
                                                !text.toLowerCase().includes('shipping')) {
                                                
                                                priceText = text.trim();
                                                const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                                if (match) {
                                                    price = parseFloat(match[1].replace(',', ''));
                                                    break;
                                                }
                                            }
                                        }
                                    }
                                    
                                    // Get rating if available
                                    let rating = null;
                                    const ratingElement = element.querySelector('[data-test="ratings"], [data-test="star-rating"]');
                                    if (ratingElement) {
                                        // Try to extract numeric rating
                                        const ratingText = ratingElement.textContent.trim();
                                        const ratingMatch = ratingText.match(/(\\d+(\\.\\d+)?)/);
                                        if (ratingMatch) {
                                            rating = `${ratingMatch[1]} out of 5 stars`;
                                        } else {
                                            rating = ratingText;
                                        }
                                    }
                                    
                                    // Get image URL
                                    let imageUrl = null;
                                    const imageElement = element.querySelector('img');
                                    if (imageElement) {
                                        imageUrl = imageElement.src;
                                    }
                                    
                                    // Add product to results if we have at least title and URL
                                    if (title && url) {
                                        // Fix relative URLs to absolute
                                        const absoluteUrl = url.startsWith('http') ? url : 'https://www.target.com' + url;
                                        
                                        products.push({
                                            title,
                                            url: absoluteUrl,
                                            price,
                                            priceText: price ? (priceText || `$${price}`) : 'Price not available',
                                            rating: rating || 'No ratings',
                                            availability: 'In Stock', // Assumption for search results
                                            imageUrl
                                        });
                                    }
                                } catch (error) {
                                    console.error(`Error processing product element ${i}:`, error);
                                }
                            }
                            
                            return products;
                        }
                    """)
                    
                    # Take screenshot for debugging if no products found
                    if not product_data or len(product_data) == 0:
                        await page.screenshot(path="/tmp/target_search_error.png")
                        logger.warning("No products found in Target search, saved screenshot for debugging")
                        return {
                            "status": "error",
                            "message": "No products found in Target search results",
                            "source": "target"
                        }
                    
                    # Return the first valid product
                    for product in product_data:
                        if product.get("title") and product.get("url"):
                            logger.info(f"Found Target product: {product.get('title')[:30]}...")
                            return {
                                "status": "success",
                                "source": "target",
                                "url": product.get("url"),
                                "title": product.get("title"),
                                "price": product.get("price"),
                                "price_text": product.get("priceText", "Price not available"),
                                "rating": product.get("rating", "No ratings"),
                                "availability": "In Stock",  # Assume search results are in stock
                                "image_url": product.get("imageUrl")
                            }
                    
                    return {
                        "status": "error",
                        "message": "No valid products found in Target search results",
                        "source": "target"
                    }
                    
                except Exception as e:
                    logger.error(f"Error during Target search: {str(e)}")
                    await page.screenshot(path="/tmp/target_search_error.png")
                    return {
                        "status": "error",
                        "message": f"Failed to search Target: {str(e)}",
                        "source": "target"
                    }
                finally:
                    await browser.close()
                    
        except Exception as e:
            logger.error(f"Error initializing browser for Target search: {str(e)}")
            return {
                "status": "error",
                "message": f"Browser error: {str(e)}",
                "source": "target"
            }
    
    async def _get_generic_search_result(self, store_name: str, search_url: str) -> Dict[str, Any]:
        """Fallback method for any store without specific implementation."""
        logger.info(f"No specific search implementation for {store_name}")
        
        # Return error rather than generating synthetic data
        return {
            "status": "error",
            "message": f"No search implementation available for {store_name}"
        }

    async def _get_amazon_search_result(self, search_url: str) -> Dict[str, Any]:
        """Get top search result from Amazon search page using stealth techniques."""
        logger.info(f"Searching Amazon with URL: {search_url}")
        
        async with async_playwright() as p:
            # Use Chromium for better compatibility with Amazon
            browser = await p.chromium.launch(headless=True)
            
            # Create a more realistic browser context
            context = await browser.new_context(
                user_agent=random.choice(self.user_agents),
                viewport={"width": 1280, "height": 800},
                locale="en-US"
            )
            
            # Add stealth script to avoid detection
            await context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
            """)
            
            # Create page and navigate
            page = await context.new_page()
            
            try:
                # Random delay before navigation to appear more human-like
                await page.wait_for_timeout(random.randint(800, 2000))
                
                # Navigate to search page
                await page.goto(search_url, wait_until="domcontentloaded", timeout=30000)
                
                # Wait for search results to load with multiple selectors
                for selector in [
                    "[data-component-type='s-search-result']", 
                    ".s-result-item", 
                    ".sg-col-inner"
                ]:
                    try:
                        await page.wait_for_selector(selector, timeout=5000, state="visible")
                        logger.info(f"Search results found with selector: {selector}")
                        break
                    except Exception:
                        continue
                
                # Extract first few search results
                product_data = await page.evaluate("""
                    () => {
                        // Try multiple selectors for search results
                        const resultSelectors = [
                            "[data-component-type='s-search-result']", 
                            ".s-result-item:not(.AdHolder)", 
                            ".s-result-list .sg-col-inner"
                        ];
                        
                        let resultElements = [];
                        
                        // Try each selector until we find results
                        for (const selector of resultSelectors) {
                            resultElements = document.querySelectorAll(selector);
                            if (resultElements.length > 0) break;
                        }
                        
                        // Process up to 5 results
                        const results = [];
                        let processedCount = 0;
                        
                        for (let i = 0; i < resultElements.length && processedCount < 5; i++) {
                            const result = resultElements[i];
                            
                            // Skip sponsored results and other non-product items
                            if (result.innerText.includes('Sponsored') || 
                                !result.querySelector('a.a-link-normal') ||
                                result.classList.contains('AdHolder')) {
                                continue;
                            }
                            
                            // Extract product details
                            try {
                                // Get title
                                const titleElement = result.querySelector('h2 .a-link-normal') || 
                                                    result.querySelector('.a-size-medium.a-color-base') ||
                                                    result.querySelector('h2') ||
                                                    result.querySelector('.a-text-normal');
                                
                                const title = titleElement ? titleElement.innerText.trim() : null;
                                
                                // Skip if no title found
                                if (!title) continue;
                                
                                // Get product URL
                                const linkElement = result.querySelector('h2 .a-link-normal') || 
                                                  result.querySelector('.a-link-normal');
                                                  
                                const productUrl = linkElement && linkElement.href ? 
                                                 linkElement.href : null;
                                
                                // Skip if no URL found
                                if (!productUrl) continue;
                                
                                // Get price - try multiple price selectors
                                let price = null;
                                let priceText = null;
                                
                                const priceSelectors = [
                                    '.a-price .a-offscreen',
                                    '.a-price',
                                    '.a-color-price',
                                    '.a-price-whole'
                                ];
                                
                                for (const priceSelector of priceSelectors) {
                                    const priceElement = result.querySelector(priceSelector);
                                    if (priceElement) {
                                        priceText = priceElement.innerText.trim();
                                        if (priceText && priceText.includes('$')) {
                                            // Extract numeric price
                                            const priceMatch = priceText.match(/\$?([\d,]+\.?\d*)/);
                                            if (priceMatch) {
                                                price = parseFloat(priceMatch[1].replace(',', ''));
                                                break;
                                            }
                                        }
                                    }
                                }
                                
                                // Get rating
                                const ratingElement = result.querySelector('.a-icon-star-small') || 
                                                    result.querySelector('.a-icon-star');
                                                    
                                let rating = ratingElement ? ratingElement.innerText.trim() : null;
                                
                                // Get review count
                                const reviewElement = result.querySelector('.a-size-small .a-link-normal');
                                const reviewCount = reviewElement ? reviewElement.innerText.trim() : null;
                                
                                // Only add if we have at least a title and URL
                                if (title && productUrl) {
                                    results.push({
                                        title,
                                        price,
                                        price_text: priceText,
                                        url: productUrl,
                                        rating,
                                        review_count: reviewCount,
                                        source: 'amazon',
                                        availability: 'In Stock' // Assuming search results are available
                                    });
                                    
                                    processedCount++;
                                }
                            } catch (err) {
                                console.error("Error processing search result:", err);
                            }
                        }
                        
                        return results;
                    }
                """)
                
                # Take screenshot for debugging if no results
                if not product_data or len(product_data) == 0:
                    await page.screenshot(path="/tmp/amazon_search_results.png")
                    logger.warning("No search results found in Amazon search page")
                    return {
                        "status": "error",
                        "message": "No search results found on Amazon",
                        "source": "amazon"
                    }
                
                # Process the first valid result
                for result in product_data:
                    if result.get("title") and result.get("url"):
                        result["status"] = "success"
                        logger.info(f"Found Amazon alternative: {result.get('title')}")
                        return result
                
                return {
                    "status": "error",
                    "message": "No valid product found in Amazon search results",
                    "source": "amazon"
                }
                
            except Exception as e:
                logger.error(f"Error searching Amazon: {str(e)}")
                try:
                    await page.screenshot(path="/tmp/amazon_search_error.png")
                except:
                    pass
                    
                return {
                    "status": "error",
                    "message": f"Failed to search Amazon: {str(e)}",
                    "source": "amazon"
                }
            finally:
                await context.close()
                await browser.close()

    async def get_amazon_product_price(self, url: str) -> Optional[float]:
        """
        Special method focused solely on extracting the price from an Amazon product page.
        Optimized for reliability and speed in price extraction.
        
        Args:
            url: Amazon product URL
            
        Returns:
            Price as float or None if price couldn't be extracted
        """
        logger.info(f"Attempting focused price extraction for Amazon product: {url}")
        
        # First, try to extract ASIN for potential API lookup
        asin = self._extract_asin_from_url(url)
        if asin:
            logger.info(f"Extracted ASIN: {asin}")
            
            # Try Rainforest API if available (most reliable source)
            if self.use_rainforest:
                try:
                    product_data = await self._get_amazon_data_from_api(asin)
                    if product_data and product_data.get('price', {}).get('value'):
                        price = product_data.get('price', {}).get('value')
                        logger.info(f"Successfully extracted price from API: ${price}")
                        return price
                except Exception as e:
                    logger.warning(f"API price extraction failed: {e}")
        
        # If API fails or isn't available, try direct browser scraping with focused selectors
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                
                # Use a stealthy context for better success rate
                context = await browser.new_context(
                    user_agent=random.choice(self.desktop_agents),
                    viewport={"width": 1280, "height": 800}
                )
                
                # Add stealth script
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                """)
                
                page = await context.new_page()
                
                try:
                    # Go to the product page
                    await page.goto(url, wait_until="domcontentloaded", timeout=20000)
                    
                    # Wait for any one of the common price selectors
                    price_selectors = [
                        ".a-price .a-offscreen",
                        "#priceblock_ourprice",
                        ".a-color-price", 
                        ".priceToPay .a-offscreen",
                        "#corePrice_feature_div .a-offscreen"
                    ]
                    
                    for selector in price_selectors:
                        try:
                            await page.wait_for_selector(selector, timeout=1000)
                            logger.info(f"Found price element with selector: {selector}")
                            break
                        except:
                            continue
                    
                    # Extract price using various methods
                    price_text = await page.evaluate("""
                        () => {
                            // Try multiple price element selectors
                            const selectors = [
                                ".a-price .a-offscreen", 
                                "#priceblock_ourprice",
                                ".a-color-price",
                                ".priceToPay .a-offscreen",
                                "#corePrice_feature_div .a-offscreen",
                                ".a-price-whole",
                                ".a-section .a-price .a-offscreen",
                                "#price_inside_buybox",
                                "#buyNewSection .a-color-price",
                                "#priceblock_dealprice"
                            ];
                            
                            // Try each selector
                            for (const selector of selectors) {
                                const elements = document.querySelectorAll(selector);
                                for (const el of elements) {
                                    const text = el.textContent.trim();
                                    if (text && text.includes('$')) {
                                        return text;
                                    }
                                }
                            }
                            
                            // If no luck with selectors, search all elements with $ sign
                            const allElements = document.querySelectorAll('*');
                            for (const el of allElements) {
                                if (el.childNodes.length === 1 && 
                                    el.textContent && 
                                    el.textContent.includes('$') && 
                                    el.textContent.length < 15 &&
                                    !el.textContent.toLowerCase().includes('shipping') &&
                                    !el.textContent.toLowerCase().includes('free') &&
                                    !el.textContent.toLowerCase().includes('total')) {
                                    return el.textContent.trim();
                                }
                            }
                            
                            return null;
                        }
                    """)
                    
                    if price_text:
                        logger.info(f"Found price text: {price_text}")
                        
                        # Parse the price
                        price_match = re.search(r'\$?([\d,]+\.?\d*)', price_text)
                        if price_match:
                            price_str = price_match.group(1).replace(',', '')
                            price = float(price_str)
                            
                            # Sanity check
                            if 1 <= price <= 10000:
                                logger.info(f"Successfully extracted price: ${price}")
                                return price
                            else:
                                logger.warning(f"Price ${price} outside reasonable range, might be incorrect")
                    
                    # Take a screenshot for debugging
                    await page.screenshot(path="/tmp/amazon_price_extraction.png")
                    logger.info("Saved screenshot to /tmp/amazon_price_extraction.png for debugging")
                    
                    # Try one more desperate attempt - parse any text that looks like a price
                    try:
                        body_text = await page.evaluate('() => document.body.innerText')
                        all_prices = re.findall(r'\$\s*([\d,]+\.?\d*)', body_text)
                        
                        if all_prices:
                            # Filter to reasonable price ranges and take the median
                            valid_prices = [float(p.replace(',', '')) for p in all_prices 
                                           if 1 <= float(p.replace(',', '')) <= 10000]
                            
                            if valid_prices:
                                # Sort and take the median price
                                valid_prices.sort()
                                median_price = valid_prices[len(valid_prices) // 2]
                                logger.info(f"Extracted median price from page text: ${median_price}")
                                return median_price
                    except Exception as e:
                        logger.error(f"Error in final price extraction attempt: {e}")
                    
                    return None
                    
                except Exception as e:
                    logger.error(f"Error during price extraction: {str(e)}")
                    return None
                finally:
                    await browser.close()
        except Exception as e:
            logger.error(f"Failed to extract price with browser: {str(e)}")
            return None

    async def _get_walmart_search_result(self, search_url: str) -> Dict[str, Any]:
        """Get top search result from Walmart search page."""
        logger.info(f"Searching Walmart: {search_url}")
        
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                
                context = await browser.new_context(
                    user_agent=random.choice(self.user_agents),
                    viewport={"width": 1280, "height": 800}
                )
                
                # Add stealth script to avoid detection
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                """)
                
                page = await context.new_page()
                
                try:
                    # Navigate to search page
                    await page.goto(search_url, wait_until="domcontentloaded", timeout=20000)
                    
                    # Wait for search results to load
                    search_result_selectors = [
                        '[data-automation-id="product-results-list"] > div',
                        '[data-testid="search-results"]',
                        '.search-results-gridview-item'
                    ]
                    
                    for selector in search_result_selectors:
                        try:
                            await page.wait_for_selector(selector, timeout=3000)
                            logger.info(f"Found Walmart search results with selector: {selector}")
                            break
                        except Exception:
                            continue
                    
                    # Extract top search results
                    product_data = await page.evaluate("""
                        () => {
                            // Find product elements (vary by page layout)
                            const productSelectors = [
                                '[data-automation-id="product-results-list"] > div',
                                '[data-testid="search-results"] > div',
                                '.search-results-gridview-item'
                            ];
                            
                            let productElements = [];
                            for (const selector of productSelectors) {
                                const elements = document.querySelectorAll(selector);
                                if (elements.length > 0) {
                                    productElements = Array.from(elements);
                                    console.log(`Found ${elements.length} products with selector: ${selector}`);
                                    break;
                                }
                            }
                            
                            // Process only the top 3 products
                            const productLimit = Math.min(3, productElements.length);
                            const products = [];
                            
                            for (let i = 0; i < productLimit; i++) {
                                try {
                                    const element = productElements[i];
                                    
                                    // Find product link
                                    const linkElement = element.querySelector('a[link-identifier="linkProductTitle"], a[data-testid="product-title"], a');
                                    if (!linkElement) continue;
                                    
                                    // Get product URL and title
                                    const url = linkElement.href;
                                    const title = linkElement.textContent.trim();
                                    
                                    // Find price
                                    let price = null;
                                    let priceText = null;
                                    
                                    // Try various price selectors
                                    const priceSelectors = [
                                        '[data-automation-id="product-price"]',
                                        '[data-testid="price-wrap"] span[itemprop="price"]',
                                        '.price-characteristic',
                                        '[itemprop="price"]'
                                    ];
                                    
                                    for (const selector of priceSelectors) {
                                        const priceElement = element.querySelector(selector);
                                        if (priceElement) {
                                            priceText = priceElement.textContent.trim();
                                            const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                            if (match) {
                                                price = parseFloat(match[1].replace(',', ''));
                                                break;
                                            }
                                        }
                                    }
                                    
                                    // If still no price, look for any element with $ sign
                                    if (!price) {
                                        const allElements = element.querySelectorAll('*');
                                        for (const el of allElements) {
                                            const text = el.textContent;
                                            if (text && 
                                                text.includes('$') && 
                                                text.length < 15 &&
                                                !text.toLowerCase().includes('shipping')) {
                                                
                                                priceText = text.trim();
                                                const match = priceText.match(/\\$([\\d,]+\\.?\\d*)/);
                                                if (match) {
                                                    price = parseFloat(match[1].replace(',', ''));
                                                    break;
                                                }
                                            }
                                        }
                                    }
                                    
                                    // Get rating if available
                                    let rating = null;
                                    const ratingElement = element.querySelector('[data-testid="rating-stars"], [itemprop="ratingValue"]');
                                    if (ratingElement) {
                                        // Try to extract numeric rating
                                        const ratingText = ratingElement.textContent.trim();
                                        const ratingMatch = ratingText.match(/(\\d+(\\.\\d+)?)/);
                                        if (ratingMatch) {
                                            rating = `${ratingMatch[1]} out of 5 stars`;
                                        } else {
                                            rating = ratingText;
                                        }
                                    }
                                    
                                    // Get image URL
                                    let imageUrl = null;
                                    const imageElement = element.querySelector('img');
                                    if (imageElement) {
                                        imageUrl = imageElement.src;
                                    }
                                    
                                    // Add product to results if we have at least title and URL
                                    if (title && url) {
                                        products.push({
                                            title,
                                            url,
                                            price,
                                            priceText: price ? (priceText || `$${price}`) : 'Price not available',
                                            rating: rating || 'No ratings',
                                            imageUrl
                                        });
                                    }
                                } catch (error) {
                                    console.error(`Error processing product element ${i}:`, error);
                                }
                            }
                            
                            return products;
                        }
                    """)
                    
                    # Take screenshot for debugging if no products found
                    if not product_data or len(product_data) == 0:
                        await page.screenshot(path="/tmp/walmart_search_error.png")
                        logger.warning("No products found in Walmart search, saved screenshot for debugging")
                        return {
                            "status": "error",
                            "message": "No products found in Walmart search results",
                            "source": "walmart"
                        }
                    
                    # Return the first valid product
                    for product in product_data:
                        if product.get("title") and product.get("url"):
                            logger.info(f"Found Walmart product: {product.get('title')[:30]}...")
                            return {
                                "status": "success",
                                "source": "walmart",
                                "url": product.get("url"),
                                "title": product.get("title"),
                                "price": product.get("price"),
                                "price_text": product.get("priceText", "Price not available"),
                                "rating": product.get("rating", "No ratings"),
                                "availability": "In Stock",  # Assume search results are in stock
                                "image_url": product.get("imageUrl")
                            }
                    
                    return {
                        "status": "error",
                        "message": "No valid products found in Walmart search results",
                        "source": "walmart"
                    }
                except Exception as e:
                    logger.error(f"Error during Walmart search: {str(e)}")
                    try:
                        await page.screenshot(path="/tmp/walmart_search_error.png")
                    except:
                        pass
                    
                    return {
                        "status": "error",
                        "message": f"Failed to search Walmart: {str(e)}",
                        "source": "walmart"
                    }
                finally:
                    await browser.close()
        except Exception as e:
            logger.error(f"Failed to initialize browser for Walmart search: {str(e)}")
            return {
                "status": "error",
                "message": f"Browser initialization error: {str(e)}",
                "source": "walmart"
            }
